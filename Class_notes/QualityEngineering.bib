
@article{goeman_testing_2006,
	title = {Testing against a high dimensional alternative},
	volume = {68},
	issn = {1467-9868},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2006.00551.x/abstract},
	doi = {10.1111/j.1467-9868.2006.00551.x},
	abstract = {Summary.  As the dimensionality of the alternative hypothesis increases, the power of classical tests tends to diminish quite rapidly. This is especially true for high dimensional data in which there are more parameters than observations. We discuss a score test on a hyperparameter in an empirical Bayesian model as an alternative to classical tests. It gives a general test statistic which can be used to test a point null hypothesis against a high dimensional alternative, even when the number of parameters exceeds the number of samples. This test will be shown to have optimal power on average in a neighbourhood of the null hypothesis, which makes it a proper generalization of the locally most powerful test to multiple dimensions. To illustrate this new locally most powerful test we investigate the case of testing the global null hypothesis in a linear regression model in more detail. The score test is shown to have significantly more power than the F-test whenever under the alternative the large variance principal components of the design matrix explain substantially more of the variance of the outcome than do the small variance principal components. The score test is also useful for detecting sparse alternatives in truly high dimensional data, where its power is comparable with the test based on the maximum absolute t-statistic.},
	language = {en},
	number = {3},
	urldate = {2016-02-02},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Goeman, Jelle J. and Van De Geer, Sara A. and Van Houwelingen, Hans C.},
	month = jun,
	year = {2006},
	keywords = {Empirical Bayes modelling, F-test, High dimensional data, Hypothesis testing, Locally most powerful test, Power, Score test},
	pages = {477--493},
	file = {Goeman et al_2006_Testing against a high dimensional alternative.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/8C4IWRI6/Goeman et al_2006_Testing against a high dimensional alternative.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/5UCM6VBI/full.html:text/html}
}

@book{qiu_introduction_2013,
	address = {Boca Raton},
	title = {Introduction to {Statistical} {Process} {Control}},
	isbn = {978-1-4398-4799-2},
	abstract = {A major tool for quality control and management, statistical process control (SPC) monitors sequential processes, such as production lines and Internet traffic, to ensure that they work stably and satisfactorily. Along with covering traditional methods, Introduction to Statistical Process Control describes many recent SPC methods that improve upon the more established techniques. The author{\textemdash}a leading researcher on SPC{\textemdash}shows how these methods can handle new applications.  After exploring the role of SPC and other statistical methods in quality control and management, the book covers basic statistical concepts and methods useful in SPC. It then systematically describes traditional SPC charts, including the Shewhart, CUSUM, and EWMA charts, as well as recent control charts based on change-point detection and fundamental multivariate SPC charts under the normality assumption. The text also introduces novel univariate and multivariate control charts for cases when the normality assumption is invalid and discusses control charts for profile monitoring. All computations in the examples are solved using R, with R functions and datasets available for download on the author{\textquoteright}s website.   Offering a systematic description of both traditional and newer SPC methods, this book is ideal as a primary textbook for a one-semester course in disciplines concerned with process quality control, such as statistics, industrial and systems engineering, and management sciences. It can also be used as a supplemental textbook for courses on quality improvement and system management. In addition, the book provides researchers with many useful, recent research results on SPC and gives quality control practitioners helpful guidelines on implementing up-to-date SPC techniques.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {Qiu, Peihua},
	month = oct,
	year = {2013}
}

@article{marc_vandemeulebroecke_group_2008,
	title = {Group {Sequential} and {Adaptive} {Designs} - {A} {Review} of {Basic} {Concepts} and {Points} of {Discussion}},
	volume = {50},
	url = {http://dx.doi.org/10.1002/bimj.200710436},
	doi = {10.1002/bimj.200710436},
	abstract = {In recent times, group sequential and adaptive designs for clinical trials have attracted great attention from industry, academia and regulatory authorities. These designs allow analyses on accumulating data - as opposed to classical, ldquofixed-samplerdquo statistics. The rapid development of a great variety of statistical procedures is accompanied by a lively debate on their potential merits and shortcomings. The purpose of this review article is to ease orientation in both respects. First, we provide a concise overview of the essential technical concepts, with special emphasis on their interrelationships. Second, we give a structured review of the current controversial discussion on practical issues, opportunities and challenges of these new designs. ({\textcopyright} 2008 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
	number = {4},
	urldate = {2009-08-08},
	journal = {Biometrical Journal},
	author = {{Marc Vandemeulebroecke}},
	year = {2008},
	keywords = {Adaptive design, Adaptive Designs, Combination test, Conditional error function, DOE, Flexible design, Group sequential design, Interim analysis, Review, Sequential analysis, Spending function, Statistics, Trial integrity, Trial validity},
	pages = {541--557},
	file = {Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/QZ9UZ5BP/Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:application/pdf;Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/VTFZ693X/Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/FI9J8SUC/abstract\;jsessionid=524233E08375CE22D0BE5CE6254ADA07.html:text/html}
}

@article{donoho_higher_2004,
	title = {Higher criticism for detecting sparse heterogeneous mixtures},
	volume = {32},
	issn = {0090-5364},
	doi = {10.1214/009053604000000265},
	number = {3},
	journal = {Annals of Statistics},
	author = {Donoho, D. and Jin, J. S.},
	month = jun,
	year = {2004},
	note = {WOS:000221981400005},
	pages = {962--994},
	file = {Donoho_Jin_2004_Higher criticism for detecting sparse heterogeneous mixtures.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/V9WM9RC5/Donoho_Jin_2004_Higher criticism for detecting sparse heterogeneous mixtures.pdf:application/pdf}
}

@article{wassmer_basic_2000,
	title = {Basic concepts of group sequential and adaptive group sequential test procedures},
	volume = {41},
	url = {http://dx.doi.org/10.1007/BF02925923},
	doi = {10.1007/BF02925923},
	abstract = {Abstract  Based on the concept of repeated significance tests, an empirical study may be planned in subsequent stages. Group sequential
test procedures offer the possibility of performing the study with a fixed number of observations per stage. At least, the
number of observations must be chosen independently of the observed data. In adaptive group sequential test procedures, the
number of observations can be changed during the course of the study using all results observed so far. In this article, the
basic concepts of these two designs are reviewed. Recent developments in adaptive designs are outlined and potential fields
of application are given.},
	number = {3},
	urldate = {2009-08-08},
	journal = {Statistical Papers},
	author = {Wassmer, Gernot},
	month = jul,
	year = {2000},
	pages = {253--279},
	file = {SpringerLink Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/7GZH98B3/317785344unk3674.html:text/html;Wassmer_2000_Basic concepts of group sequential and adaptive group sequential test procedures.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/PG6PMQG2/Wassmer_2000_Basic concepts of group sequential and adaptive group sequential test procedures.pdf:application/pdf}
}

@book{petersen_matrix_2006,
	title = {The matrix cookbook},
	publisher = {Citeseer},
	author = {Petersen, K. B and Pedersen, M. S},
	year = {2006},
	keywords = {Mathematics}
}

@book{fujikoshi_multivariate_2010,
	address = {Wiley},
	edition = {1 edition},
	title = {Multivariate {Statistics}: {High}-{Dimensional} and {Large}-{Sample} {Approximations}},
	isbn = {978-0-470-41169-8},
	shorttitle = {Multivariate {Statistics}},
	abstract = {Written by well-known, award-winning authors, this is the first book to focus on high-dimensional data analysis while presenting real-world applications and research material. Emphasizing that high-dimensional asymptotic distribution can be used for a large range of samples and dimensions to achieve high levels of accuracy, this timely text provides approximation formulas, actual applications, thorough analysis of the real data, and solutions to each problem that are useful to both practical and theoretical statisticians as well as graduate students.},
	language = {English},
	publisher = {Wiley},
	author = {Fujikoshi, Yasunori and Ulyanov, Vladimir V. and Shimizu, Ryoichi},
	month = jan,
	year = {2010}
}

@article{jin_cosmological_2005,
	title = {Cosmological non-{Gaussian} {Signature} {Detection}: {Comparing} {Performance} of {Different} {Statistical} {Tests}},
	volume = {2005},
	issn = {1110-8657},
	shorttitle = {Cosmological non-{Gaussian} {Signature} {Detection}},
	url = {http://dx.doi.org/10.1155/ASP.2005.2470},
	doi = {10.1155/ASP.2005.2470},
	urldate = {2014-09-01},
	journal = {EURASIP J. Appl. Signal Process.},
	author = {Jin, J. and Starck, J.-L. and Donoho, D. L. and Aghanim, N. and Forni, O.},
	month = jan,
	year = {2005},
	keywords = {cosmological microwave background, cosmology, curvelet, multiscale method, non-Gaussianity detection, wavelet},
	pages = {2470--2485},
	file = {Jin et al_2005_Cosmological non-Gaussian Signature Detection.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/8QDFXAZJ/Jin et al_2005_Cosmological non-Gaussian Signature Detection.pdf:application/pdf}
}

@book{meyer_matrix_2001,
	address = {Philadelphia},
	edition = {Har/Cdr edition},
	title = {Matrix {Analysis} and {Applied} {Linear} {Algebra} {Book} and {Solutions} {Manual}},
	isbn = {978-0-89871-454-8},
	abstract = {This book avoids the traditional definition-theorem-proof format; instead a fresh approach introduces a variety of problems and examples all in a clear and informal style. The in-depth focus on applications separates this book from others, and helps students to see how linear algebra can be applied to real-life situations. Some of the more contemporary topics of applied linear algebra are included here which are not normally found in undergraduate textbooks. Theoretical developments are always accompanied with detailed examples, and each section ends with a number of exercises from which students can gain further insight. Moreover, the inclusion of historical information provides personal insights into the mathematicians who developed this subject. The textbook contains numerous examples and exercises, historical notes, and comments on numerical performance and the possible pitfalls of algorithms. Solutions to all of the exercises are provided, as well as a CD-ROM containing a searchable copy of the textbook.},
	language = {English},
	publisher = {SIAM: Society for Industrial and Applied Mathematics},
	author = {Meyer, Carl D.},
	month = feb,
	year = {2001}
}

@book{anderson_introduction_2003,
	address = {Hoboken, NJ},
	edition = {3 edition},
	title = {An {Introduction} to {Multivariate} {Statistical} {Analysis}},
	isbn = {978-0-471-36091-9},
	abstract = {Perfected over three editions and more than forty years, this field- and classroom-tested reference: * Uses the method of maximum likelihood to a large extent to ensure reasonable, and in some cases optimal procedures. * Treats all the basic and important topics in multivariate statistics. * Adds two new chapters, along with a number of new sections. * Provides the most methodical, up-to-date information on MV statistics available.},
	language = {English},
	publisher = {Wiley-Interscience},
	author = {Anderson, T. W.},
	month = jul,
	year = {2003}
}

@article{srivastava_two_2013,
	title = {A two sample test in high dimensional data},
	volume = {114},
	issn = {0047-259X},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X12002126},
	doi = {10.1016/j.jmva.2012.08.014},
	abstract = {In this paper we propose a test for testing the equality of the mean vectors of two groups with unequal covariance matrices based on N 1 and N 2 independently distributed p -dimensional observation vectors. It will be assumed that N 1 observation vectors from the first group are normally distributed with mean vector $\mu$ 1 and covariance matrix $\Sigma$ 1 . Similarly, the N 2 observation vectors from the second group are normally distributed with mean vector $\mu$ 2 and covariance matrix $\Sigma$ 2 . We propose a test for testing the hypothesis that $\mu$ 1 = $\mu$ 2 . This test is invariant under the group of p {\texttimes} p nonsingular diagonal matrices. The asymptotic distribution is obtained as ( N 1 , N 2 , p ) {\textrightarrow} $\infty$ and N 1 / ( N 1 + N 2 ) {\textrightarrow} k ? ( 0 , 1 ) but N 1 / p and N 2 / p may go to zero or infinity. It is compared with a recently proposed non-invariant test. It is shown that the proposed test performs the best.},
	urldate = {2015-05-31},
	journal = {Journal of Multivariate Analysis},
	author = {Srivastava, Muni S. and Katayama, Shota and Kano, Yutaka},
	month = feb,
	year = {2013},
	keywords = {Asymptotic theory, Behrens{\textendash}Fisher problem, High-dimensional data, Hypothesis testing},
	pages = {349--358},
	file = {ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/T8KIS5U9/S0047259X12002126.html:text/html;Srivastava et al_2013_A two sample test in high dimensional data.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/HITJM4F3/Srivastava et al_2013_A two sample test in high dimensional data.pdf:application/pdf}
}

@article{srivastava_testing_2013,
	title = {On testing the equality of mean vectors in high dimension},
	volume = {17},
	issn = {2228-4699},
	url = {http://acutm.math.ut.ee/index.php/acutm/article/view/ACUTM.2013.17.03},
	doi = {10.12697/ACUTM.2013.17.03},
	abstract = {In this article, we review various tests that have been proposed in the literature for testing the equality of several mean vectors. In particular, it includes testing the equality of two mean vectors, the so-called two-sample problem as well as that of testing the equality of several mean vectors, the so-called multivariate analysis of variance or MANOVA problem. The total sample size, however, may be less than the dimension of the mean vectors, and so usual tests cannot be used. Powers of these tests are compared using simulation.},
	language = {en},
	number = {1},
	urldate = {2015-06-01},
	journal = {Acta et Commentationes Universitatis Tartuensis de Mathematica},
	author = {Srivastava, Muni S.},
	month = jun,
	year = {2013},
	keywords = {Equality of two mean vectors, high dimensional, inequality of two covariance matrices, Multivariate analysis of variance, sample smaller than dimension},
	pages = {31--56},
	file = {Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/52BRBUCE/ACUTM.2013.17.html:text/html;Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/CES3WQ63/Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:application/pdf}
}

@article{srivastava_multivariate_2006,
	series = {Special {Issue} dedicated to {Prof}. {Fujikoshi}},
	title = {Multivariate analysis of variance with fewer observations than the dimension},
	volume = {97},
	issn = {0047-259X},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X06000777},
	doi = {10.1016/j.jmva.2005.08.010},
	abstract = {In this article, we consider the problem of testing a linear hypothesis in a multivariate linear regression model which includes the case of testing the equality of mean vectors of several multivariate normal populations with common covariance matrix $\Sigma$ , the so-called multivariate analysis of variance or MANOVA problem. However, we have fewer observations than the dimension of the random vectors. Two tests are proposed and their asymptotic distributions under the hypothesis as well as under the alternatives are given under some mild conditions. A theoretical comparison of these powers is made.},
	number = {9},
	urldate = {2015-05-31},
	journal = {Journal of Multivariate Analysis},
	author = {Srivastava, Muni S. and Fujikoshi, Yasunori},
	month = oct,
	year = {2006},
	keywords = {Distribution of test statistics, DNA microarray data, Fewer observations than dimension, Moore{\textendash}Penrose inverse, Multivariate analysis of variance, Singular Wishart},
	pages = {1927--1940},
	file = {ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ZFRXZHMG/S0047259X06000777.html:text/html;Srivastava_Fujikoshi_2006_Multivariate analysis of variance with fewer observations than the dimension.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/EWAGCUD5/Srivastava_Fujikoshi_2006_Multivariate analysis of variance with fewer observations than the dimension.pdf:application/pdf}
}

@article{srivastava_test_2009,
	title = {A test for the mean vector with fewer observations than the dimension under non-normality},
	volume = {100},
	issn = {0047-259X},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X08001528},
	doi = {10.1016/j.jmva.2008.06.006},
	abstract = {In this article, we consider the problem of testing that the mean vector $\mu$ = 0 in the model x j = $\mu$ + C z j , j = 1 , {\textellipsis} , N , where z j are random p -vectors, z j = ( z i j , {\textellipsis} , z p j ) ' and z i j are independently and identically distributed with finite four moments, i = 1 , {\textellipsis} , p , j = 1 , {\textellipsis} , N ; that is x i need not be normally distributed. We shall assume that C is a p {\texttimes} p non-singular matrix, and there are fewer observations than the dimension, N <= p . We consider the test statistic T = [ N x {\textasciimacron} ' D s - 1 x {\textasciimacron} - n p / ( n - 2 ) ] / [ 2 tr R 2 - p 2 / n ] 1 2 , where x {\textasciimacron} is the sample mean vector, S = ( s i j ) is the sample covariance matrix, D S = diag ( s 11 , {\textellipsis} , s p p ) , R = D s - 1 2 S D s - 1 2 and n = N - 1 . The asymptotic null and non-null distributions of the test statistic T are derived.},
	number = {3},
	urldate = {2015-05-31},
	journal = {Journal of Multivariate Analysis},
	author = {Srivastava, Muni S.},
	month = mar,
	year = {2009},
	keywords = {62H10, 62H15, Asymptotic null and non-null distribution, Fewer observations, High dimension, Non-normality, Testing mean vector},
	pages = {518--532},
	file = {ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/7CIBT3PK/S0047259X08001528.html:text/html;Srivastava_2009_A test for the mean vector with fewer observations than the dimension under.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/WV4NJV6T/Srivastava_2009_A test for the mean vector with fewer observations than the dimension under.pdf:application/pdf}
}

@article{srivastava_test_2008,
	title = {A test for the mean vector with fewer observations than the dimension},
	volume = {99},
	issn = {0047-259X},
	url = {http://www.sciencedirect.com/science/article/pii/S0047259X06001990},
	doi = {10.1016/j.jmva.2006.11.002},
	abstract = {In this paper, we consider a test for the mean vector of independent and identically distributed multivariate normal random vectors where the dimension p is larger than or equal to the number of observations N. This test is invariant under scalar transformations of each component of the random vector. Theories and simulation results show that the proposed test is superior to other two tests available in the literature. Interest in such significance test for high-dimensional data is motivated by DNA microarrays. However, the methodology is valid for any application which involves high-dimensional data.},
	number = {3},
	urldate = {2015-06-01},
	journal = {Journal of Multivariate Analysis},
	author = {Srivastava, Muni S. and Du, Meng},
	month = mar,
	year = {2008},
	keywords = {Asymptotic distribution, DNA microarray, Multivariate normal, Power comparison, Significance test},
	pages = {386--402},
	file = {ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ZM7JH2QS/S0047259X06001990.html:text/html;Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/7GXHRAJV/Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:application/pdf}
}

@article{fuchs_multivariate_1994,
	title = {Multivariate {Profile} {Charts} for {Statistical} {Process} {Control}},
	volume = {36},
	issn = {0040-1706},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1994.10485765},
	doi = {10.1080/00401706.1994.10485765},
	abstract = {The multivariate profile (MP) chart is a new control chart for simultaneous display of univariate and multivariate statistics. It is designed to analyze and display extended structures of statistical process control data for various cases of grouping, reference distribution, and use of nominal specifications. For each group of observations, the scaled deviations from reference values are portrayed together as a modified profile plot symbol. The vertical location of the symbol is determined by the multivariate distance of the vector of means from the reference values. The graphical display in the MP chart enjoys improved visual characteristics as compared with previously suggested methods. Moreover, the perceptual tasks required by the use of the MP chart provide higher accuracy in retrieving the quantitative information. This graphical display is used to display other combined univariate and multivariate statistics, such as measures of dispersion, principal components, and cumulative sums},
	number = {2},
	urldate = {2015-06-03},
	journal = {Technometrics},
	author = {Fuchs, Camil and Benjamini, Yoav},
	month = may,
	year = {1994},
	pages = {182--195},
	file = {Fuchs_Benjamini_1994_Multivariate Profile Charts for Statistical Process Control.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/DJ7R8XGJ/Fuchs_Benjamini_1994_Multivariate Profile Charts for Statistical Process Control.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/Q5K5SQRG/00401706.1994.html:text/html}
}

@article{hotelling_generalization_1931,
	title = {The {Generalization} of {Student}'s {Ratio}},
	volume = {2},
	issn = {0003-4851, 2168-8990},
	url = {http://projecteuclid.org/euclid.aoms/1177732979},
	doi = {10.1214/aoms/1177732979},
	abstract = {Project Euclid - mathematics and statistics online},
	language = {EN},
	number = {3},
	urldate = {2015-06-19},
	journal = {The Annals of Mathematical Statistics},
	author = {Hotelling, Harold},
	month = aug,
	year = {1931},
	pages = {360--378},
	file = {Hotelling_1931_The Generalization of Student's Ratio.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/2HEC4VV3/Hotelling_1931_The Generalization of Student's Ratio.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/VH7S648S/1177732979.html:text/html;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/MRVQTBMM/1177732979.html:text/html}
}

@book{montgomery_statistical_2012,
	address = {Hoboken, NJ},
	edition = {7 edition},
	title = {Statistical {Quality} {Control}},
	isbn = {978-1-118-14681-1},
	language = {English},
	publisher = {Wiley},
	author = {Montgomery, Douglas C.},
	month = jun,
	year = {2012}
}

@book{_modern_2001,
	address = {New York},
	edition = {2 edition},
	title = {Modern {Methods} {For} {Quality} {Control} and {Improvement}},
	isbn = {978-0-471-29973-8},
	language = {English},
	publisher = {Wiley},
	month = nov,
	year = {2001}
}

@book{acheson_j._duncan_quality_1986,
	address = {Homewood, Ill},
	edition = {5 edition},
	title = {Quality {Control} and {Industrial} {Statistics}. {Fifth} {Edition}},
	isbn = {978-0-256-03535-3},
	language = {English},
	publisher = {Irwin},
	author = {{Acheson J. Duncan}},
	month = jan,
	year = {1986},
	keywords = {Technology \& Engineering / Industrial Engineering}
}

@book{_jurans_1988,
	address = {New York},
	title = {Juran's {Quality} {Control} {Handbook}},
	isbn = {978-0-07-033176-1},
	language = {English},
	publisher = {Mcgraw-Hill},
	month = aug,
	year = {1988}
}

@book{wheeler_understanding_2010,
	address = {Knoxville, Tenn},
	title = {Understanding {Statistical} {Process} {Control}},
	isbn = {978-0-945320-69-2},
	language = {English},
	publisher = {SPC PRESS},
	author = {Wheeler, Donald J.},
	month = jun,
	year = {2010}
}

@misc{_yhat_????,
	title = {{\^y}hat {\textbar} {Statistical} {Quality} {Control} in {R}},
	url = {http://blog.yhathq.com/posts/quality-control-in-r.html},
	abstract = {Quality Control and quality assurance are important functions in most businesses from manufacturing to software development. For most, this means that one or more people are meticulously inspecting what's coming out of the factory, looking for imperfections and validating that requirements for products and services produced are satisfied. Often times QC and QA are performed manually by a select few specialists, and determining suitable quality can be extremely complex and error-prone.

This is a post about quality assurance automation ...},
	urldate = {2015-07-22},
	journal = {{\^y}hat {\textbar} Blog},
	file = {Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/BBENXMQI/quality-control-in-r.html:text/html}
}

@book{wikipedia_optimal_2015,
	title = {Optimal design {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Optimal_design&oldid=675412903},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 13-November-2015]}
}

@article{wald_sequential_1945,
	title = {Sequential tests of statistical hypotheses},
	volume = {16},
	url = {http://www.jstor.org/stable/2235829},
	number = {2},
	urldate = {2015-11-13},
	journal = {The Annals of Mathematical Statistics},
	author = {Wald, Abraham},
	year = {1945},
	pages = {117--186}
}

@book{barlow_mathematical_1965,
	title = {Mathematical {Theory} of {Reliability}},
	isbn = {978-0-471-04965-4},
	abstract = {This monograph presents a survey of mathematical models useful in solving reliability problems. It includes a detailed discussion of life distributions corresponding to wearout and their use in determining maintenance policies, and covers important topics such as the theory of increasing (decreasing) failure rate distributions, optimum maintenance policies, and the theory of coherent systems. The emphasis throughout the book is on making minimal assumptions - and only those based on plausible physical considerations - so that the resulting mathematical deductions may be safely made about a large variety of commonly occurring reliability situations. The first part of the book is concerned with component reliability, while the second part covers system reliability, including problems that are as important today as they were in the 1960s. The enduring relevance of the subject of reliability and the continuing demand for a graduate-level book on this topic are the driving forces behind its re-publication.},
	language = {en},
	publisher = {Wiley},
	author = {Barlow, Richard E. and Proschan, Frank},
	month = jan,
	year = {1965}
}

@article{sacks_design_1989,
	title = {Design and analysis of computer experiments},
	url = {http://www.jstor.org/stable/2245858},
	urldate = {2015-11-13},
	journal = {Statistical science},
	author = {Sacks, Jerome and Welch, William J. and Mitchell, Toby J. and Wynn, Henry P.},
	year = {1989},
	pages = {409--423}
}

@book{_process_1998,
	address = {London ; New York},
	title = {Process {Capability} {Indices} in {Theory} and {Practice}},
	isbn = {978-0-340-69177-9},
	language = {English},
	publisher = {Hodder Education Publishers},
	month = oct,
	year = {1998}
}

@book{_encyclopedia_2006,
	address = {Singapore ; Hackensack, NJ},
	title = {Encyclopedia {And} {Handbook} of {Process} {Capability} {Indices}: {A} {Comprehensive} {Exposition} of {Quality} {Control} {Measures}},
	isbn = {978-981-256-759-8},
	shorttitle = {Encyclopedia {And} {Handbook} of {Process} {Capability} {Indices}},
	language = {English},
	publisher = {World Scientific Pub Co Inc},
	month = may,
	year = {2006}
}

@article{masuda_multivariate_2014,
	title = {Multivariate {Statistical} {Process} {Control} {Method} {Including} {Soft} {Sensors} for {Both} {Early} and {Accurate} {Fault} {Detection}},
	volume = {53},
	issn = {0888-5885},
	url = {http://dx.doi.org/10.1021/ie501024w},
	doi = {10.1021/ie501024w},
	abstract = {The development of process monitoring and control methods is important to maintaining product quality in chemical plants safely and effectively. Therefore, multivariate statistical process control (MSPC) methods have been developed, but traditional MSPC methods cannot detect faults relating to process variables that are difficult to measure online. In this work, a new MSPC method including soft sensor prediction is proposed to solve this problem. Soft sensors predict values of difficult-to-measure variables that are used as input variables of fault detection models. The proposed method enables the real-time control of processes using difficult-to-measure variables. The fault detection performance of the proposed method is demonstrated and compared with that of traditional MSPC methods using the Tennessee Eastman process and real industrial process data sets. The results show that the proposed method can achieve more accurate and earlier fault detection than traditional MSPC methods.},
	number = {20},
	urldate = {2015-10-28},
	journal = {Industrial \& Engineering Chemistry Research},
	author = {Masuda, Yasuyuki and Kaneko, Hiromasa and Funatsu, Kimito},
	month = may,
	year = {2014},
	pages = {8553--8564},
	file = {ACS Full Text Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/D8PSVH6V/ie501024w.html:text/html}
}

@book{montgomery_introduction_2007,
	title = {Introduction to statistical quality control},
	publisher = {John Wiley \& Sons},
	author = {Montgomery, Douglas C},
	year = {2007}
}

@book{wikipedia_quality_2015,
	title = {Quality (business) {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Quality_(business)&oldid=682960115},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 28-October-2015]}
}

@book{wikipedia_eight_2015,
	title = {Eight dimensions of quality {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Eight_dimensions_of_quality&oldid=685390671},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 28-October-2015]}
}

@book{wikipedia_zero_2015,
	title = {Zero {Defects} {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Zero_Defects&oldid=668207586},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 29-October-2015]}
}

@book{wikipedia_value_2015,
	title = {Value engineering {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Value_engineering&oldid=676994647},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 29-October-2015]}
}

@book{wikipedia_lean_2015,
	title = {Lean manufacturing {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Lean_manufacturing&oldid=687646421},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 29-October-2015]}
}

@book{wikipedia_design_2015,
	title = {Design for {Six} {Sigma} {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Design_for_Six_Sigma&oldid=683747970},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 29-October-2015]}
}

@article{rodgers_thirteen_1988,
	title = {Thirteen {Ways} to {Look} at the {Correlation} {Coefficient}},
	volume = {42},
	issn = {0003-1305},
	url = {http://dx.doi.org/10.1080/00031305.1988.10475524},
	doi = {10.1080/00031305.1988.10475524},
	abstract = {In 1885, Sir Francis Galton first defined the term {\textquotedblleft}regression{\textquotedblright} and completed the theory of bivariate correlation. A decade later, Karl Pearson developed the index that we still use to measure correlation, Pearson's r. Our article is written in recognition of the 100th anniversary of Galton's first discussion of regression and correlation. We begin with a brief history. Then we present 13 different formulas, each of which represents a different computational and conceptual definition of r. Each formula suggests a different way of thinking about this index, from algebraic, geometric, and trigonometric settings. We show that Pearson's r (or simple functions of r) may variously be thought of as a special type of mean, a special type of variance, the ratio of two means, the ratio of two variances, the slope of a line, the cosine of an angle, and the tangent to an ellipse, and may be looked at from several other interesting perspectives.},
	number = {1},
	urldate = {2015-10-29},
	journal = {The American Statistician},
	author = {Rodgers, Joseph Lee and Nicewander, W. Alan},
	month = feb,
	year = {1988},
	pages = {59--66},
	file = {Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/NDQAD5TU/00031305.1988.html:text/html}
}

@article{woodall_controversies_2000,
	title = {Controversies and contradictions in statistical process control},
	volume = {32},
	url = {http://myplace.frontier.com/~stevebrainerd1/STATISTICS/ECE-580-DOE%20WEEK%203_files/Woodall%20paper%20Control%20charts.pdf},
	number = {4},
	urldate = {2015-11-01},
	journal = {Journal of Quality Technology},
	author = {Woodall, William H.},
	year = {2000},
	pages = {341--350},
	file = {Woodall_2000_Controversies and contradictions in statistical process control.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/PI5ZQPCJ/Woodall_2000_Controversies and contradictions in statistical process control.pdf:application/pdf}
}

@book{hawkins_cumulative_1998,
	address = {New York},
	edition = {1998 edition},
	title = {Cumulative {Sum} {Charts} and {Charting} for {Quality} {Improvement}},
	isbn = {978-0-387-98365-3},
	language = {English},
	publisher = {Springer},
	author = {Hawkins, Douglas M. and Olwell, David H.},
	month = jan,
	year = {1998}
}

@book{basseville_detection_1993,
	title = {Detection of abrupt changes: theory and application},
	volume = {104},
	shorttitle = {Detection of abrupt changes},
	url = {ftp://ftp.irisa.fr/local/as/mb/k11.pdf},
	urldate = {2015-11-04},
	publisher = {Prentice Hall Englewood Cliffs},
	author = {Basseville, Mich{\`e}le and Nikiforov, Igor V. and {others}},
	year = {1993}
}

@article{ritov_decision_1990,
	title = {Decision {Theoretic} {Optimality} of the {Cusum} {Procedure}},
	volume = {18},
	copyright = {Copyright {\textcopyright} 1990 Institute of Mathematical Statistics},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/2242064},
	abstract = {Suppose X1, X2, ... are independent random variables such that for some unknown $\nu$, each of X1, ..., X$\nu$ - 1 is distributed according to F0, while X$\nu$, X$\nu$ + 1, ... are all distributed according to F1. We prove a result of Moustakides that claims that the CUSUM procedures are optimal in the sense of Lorden. We do that by proving that the procedures are Bayes for some stochastic mechanism of generating $\nu$.},
	number = {3},
	urldate = {2015-11-04},
	journal = {The Annals of Statistics},
	author = {Ritov, Y.},
	month = sep,
	year = {1990},
	pages = {1464--1469},
	file = {Ritov_1990_Decision Theoretic Optimality of the Cusum Procedure.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TGN729EP/Ritov_1990_Decision Theoretic Optimality of the Cusum Procedure.pdf:application/pdf}
}

@article{page_continuous_1954,
	title = {Continuous {Inspection} {Schemes}},
	volume = {41},
	issn = {0006-3444, 1464-3510},
	url = {http://biomet.oxfordjournals.org/content/41/1-2/100},
	doi = {10.1093/biomet/41.1-2.100},
	language = {en},
	number = {1-2},
	urldate = {2015-11-04},
	journal = {Biometrika},
	author = {Page, E. S.},
	month = jun,
	year = {1954},
	pages = {100--115},
	file = {Page_1954_Continuous Inspection Schemes.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/2CTNDXHR/Page_1954_Continuous Inspection Schemes.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ZV3BPNE7/100.html:text/html}
}

@book{wikipedia_receiver_2015,
	title = {Receiver operating characteristic {\textemdash} {Wikipedia}, {The} {Free} {Encyclopedia}},
	url = {https://en.wikipedia.org/w/index.php?title=Receiver_operating_characteristic&oldid=689009118},
	author = {{Wikipedia}},
	year = {2015},
	note = {[Online; accessed 6-November-2015]}
}

@article{woodall_statistical_1993,
	title = {The {Statistical} {Design} of {Cusum} {Charts}},
	volume = {5},
	issn = {0898-2112},
	url = {http://dx.doi.org/10.1080/08982119308918998},
	doi = {10.1080/08982119308918998},
	number = {4},
	urldate = {2015-11-06},
	journal = {Quality Engineering},
	author = {WOODALL, WILLIAM H. and ADAMS, BENJAMIN M.},
	month = jan,
	year = {1993},
	pages = {559--570},
	file = {Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/EMJN6935/08982119308918998.html:text/html}
}

@book{natrella_nist/sematech_2010,
	title = {{NIST}/{SEMATECH} e-{Handbook} of {Statistical} {Methods}},
	url = {http://www.itl.nist.gov/div898/handbook/},
	abstract = {The NIST/SEMATECH e-Handbook of Statistical Methods1, is a Web-based book whose goal is to help scientists and engineers incorporate statistical methods into their work as  efficiently as possible. Ideally it will serve as a reference that will help scientists and engineers design their own experiments and carry out the appropriate analyses when a statistician is not available to help. It is also hoped that it will serve as a useful educational tool that will help users of statistical methods and consumers of statistical information better understand statistical procedures and their underlying assumptions and more clearly interpret scientific and engineering results stated in statistical terms.},
	urldate = {2015-11-08},
	publisher = {NIST/SEMATECH},
	author = {Natrella, Mary},
	editor = {Croarkin, Carroll and Tobias, Paul and Filliben, James and Hembree, Barry and Guthrie, William and Trutna, Ledi and Prins, Jack},
	month = jul,
	year = {2010},
	keywords = {e-handbook, nist, sematech, statistical\_methods}
}

@article{moustakides_optimal_1986,
	title = {Optimal {Stopping} {Times} for {Detecting} {Changes} in {Distributions}},
	volume = {14},
	copyright = {Copyright {\textcopyright} 1986 Institute of Mathematical Statistics},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/2241476},
	abstract = {It is shown that Page's stopping time is optimal for the detection of changes in distributions, in a well defined sense. This work is a generalization of an existing result where it was shown that Page's stopping time is optimal asymptotically.},
	number = {4},
	urldate = {2015-11-06},
	journal = {The Annals of Statistics},
	author = {Moustakides, George V.},
	month = dec,
	year = {1986},
	pages = {1379--1387},
	file = {Moustakides_1986_Optimal Stopping Times for Detecting Changes in Distributions.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ZENHCXPR/Moustakides_1986_Optimal Stopping Times for Detecting Changes in Distributions.pdf:application/pdf}
}

@article{moustakides_optimality_2004,
	title = {Optimality of the {CUSUM} {Procedure} in {Continuous} {Time}},
	volume = {32},
	copyright = {Copyright {\textcopyright} 2004 Institute of Mathematical Statistics},
	issn = {0090-5364},
	url = {http://www.jstor.org/stable/3448511},
	abstract = {The optimality of CUSUM under a Lorden-type criterion setting is considered. We demonstrate the optimality of the CUSUM test for It{\^o} processes, in a sense similar to Lorden's, but with a criterion that replaces expected delays by the corresponding Kullback-Leibler divergence.},
	number = {1},
	urldate = {2015-11-06},
	journal = {The Annals of Statistics},
	author = {Moustakides, George V.},
	month = feb,
	year = {2004},
	pages = {302--315},
	file = {Moustakides_2004_Optimality of the CUSUM Procedure in Continuous Time.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/2T3DQP5X/Moustakides_2004_Optimality of the CUSUM Procedure in Continuous Time.pdf:application/pdf}
}

@incollection{umit_multivariate_2001,
	title = {Multivariate {Quality} {Control}: {A} {Historical} {Perspective}.},
	shorttitle = {Multivariate {Quality} {Control}},
	publisher = {Yilditz Technical University},
	author = {Umit, F and Cigdem, A},
	year = {2001},
	keywords = {statistical\_techniques, Statistics},
	pages = {54--65},
	file = {Umit_Cigdem_2001_Multivariate Quality Control.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/HVFE82AS/Umit_Cigdem_2001_Multivariate Quality Control.pdf:application/pdf}
}

@article{berman_limit_1964,
	title = {Limit {Theorems} for the {Maximum} {Term} in {Stationary} {Sequences}},
	volume = {35},
	issn = {0003-4851, 2168-8990},
	url = {http://projecteuclid.org/euclid.aoms/1177703551},
	doi = {10.1214/aoms/1177703551},
	abstract = {Let \{Xn,n=0,{\textpm}1,?\}{\textbackslash}\{X\_n, n = 0, {\textbackslash}pm 1, {\textbackslash}cdots{\textbackslash}\} be a real valued discrete parameter stationary stochastic process on a probability space ($\Omega$,?,P);({\textbackslash}Omega, {\textbackslash}mathscr\{F\}, P); for each n=1,2,?n = 1, 2, {\textbackslash}cdots, let Zn=max(X1,?,Xn)Z\_n = {\textbackslash}max (X\_1, {\textbackslash}cdots, X\_n). We shall find general conditions under which the random variable ZnZ\_n has a limiting distribution function (d.f.) as n{\textrightarrow}$\infty$n {\textbackslash}rightarrow {\textbackslash}infty; that is, there exist sequences \{an\}{\textbackslash}\{a\_n{\textbackslash}\} and \{bn\},an{\textgreater}0{\textbackslash}\{b\_n{\textbackslash}\}, a\_n {\textgreater} 0, and a proper nondegenerate d.f. $\Phi$(x){\textbackslash}Phi(x) such that limn{\textrightarrow}$\infty$P\{Zn?anx+bn\}=$\Phi$(x)(1.1){\textbackslash}begin\{equation*\}{\textbackslash}tag\{1.1\}{\textbackslash}lim\_\{n {\textbackslash}rightarrow {\textbackslash}infty\} P{\textbackslash}\{Z\_n {\textbackslash}leqq a\_nx + b\_n{\textbackslash}\} = {\textbackslash}Phi(x){\textbackslash}end\{equation*\} for each xx in the continuity set of $\Phi$(x){\textbackslash}Phi(x). The simplest type of stationary sequence \{Xn\}{\textbackslash}\{X\_n{\textbackslash}\} is one in which the random variables are mutually independent with some common d.f. F(x)F(x). In this case, ZnZ\_n has the d.f. Fn(x)F{\textasciicircum}n(x) and (1.1) becomes limn{\textrightarrow}$\infty$Fn(anx+bn)=$\Phi$(x).(1.2){\textbackslash}begin\{equation*\}{\textbackslash}tag\{1.2\}{\textbackslash}lim\_\{n {\textbackslash}rightarrow {\textbackslash}infty\} F{\textasciicircum}n(a\_nx + b\_n) = {\textbackslash}Phi(x).{\textbackslash}end\{equation*\} It is well known that in (1.2) $\Phi$(x){\textbackslash}Phi(x) is of one of exactly three types; necessary and sufficient conditions on FF for the validity of (1.2) are also known [9]. The three types are usually called extreme value d.f.'s [10]. Theorem 2.1 gives the limiting d.f. of ZnZ\_n in a stationary sequence satisfying a certain condition on the upper tail of the conditional d.f. of X1X\_1, given the "past" of sequence: the limiting d.f. is a simple mixture of extreme value d.f.'s of a single type. These are the same kind of d.f.'s found by us [3] to be the limiting d.f.'s of maxima in sequences of exchangeable random variables. The conditions of Theorem 2.1 are specialized to exchangeable and Markov sequences, and Theorem 2.2 extends the methods of Theorem 2.1 to general (not necessarily stationary) Markov sequences. It is shown that stationary Gaussian sequences, except for the trivial case of independent, identically distributed Gaussian random variables, do not obey the requirements of the hypothesis of Theorem 2.1: hence, Sections 3, 4, and 5 are devoted to a detailed study of the maximum in a stationary Gaussian sequence. Theorem 3.1 provides conditions on the rate of convergence of the covariance sequence to 0 which are sufficient for ZnZ\_n to have the same extreme value limiting d.f. as in the case of independence, namely, exp(-e-x){\textbackslash}exp (-e{\textasciicircum}\{-x\}). The relation of these conditions to the spectral d.f. of the process is also discussed. A weaker condition on the covariance sequence ensures the "relative stability in probability" of ZnZ\_n (Theorem 4.1). Theorem 5.1 describes the behavior of ZnZ\_n when the spectrum has a discrete component with "not too many large jumps" and a "smooth" continuous component: when properly normalized, ZnZ\_n converges in probability to a random variable representing the maximum of the process corresponding to the discrete spectral component. A special case was given by us in [2]. We now summarize some known results used in the sequel. The extreme value d.f.'s are continuous, so that (1.2) holds for all xx; furthermore, this holds if and only if it holds for all xx satisfying 0{\textless}$\Phi$(x){\textless}1.0 {\textless} {\textbackslash}Phi(x) {\textless} 1. (1.2) implies that for all such xx 0{\textless}Fn(anx+bn){\textless}1,for all largen,0 {\textless} F{\textasciicircum}n (a\_nx + b\_n) {\textless} 1,{\textbackslash}quad{\textbackslash}text\{for all large\} n, and limn{\textrightarrow}$\infty$F(anx+bn)=1.(1.3){\textbackslash}begin\{equation*\}{\textbackslash}tag\{1.3\}{\textbackslash}lim\_\{n {\textbackslash}rightarrow {\textbackslash}infty\} F(a\_nx + b\_n) = 1.{\textbackslash}end\{equation*\} Let x$\infty$x\_{\textbackslash}infty be the supremum of all real numbers x'x' for which F(x'){\textless}1F(x') {\textless} 1; then, for all xx satisfying 0{\textless}$\Phi$(x){\textless}10 {\textless} {\textbackslash}Phi(x) {\textless} 1, we have limn{\textrightarrow}$\infty$anx+bn=x$\infty$.(1.4){\textbackslash}begin\{equation*\}{\textbackslash}tag\{1.4\}{\textbackslash}lim\_\{n {\textbackslash}rightarrow {\textbackslash}infty\} a\_nx + b\_n = x\_{\textbackslash}infty.{\textbackslash}end\{equation*\} From (1.3), and the asymptotic relation -logF\~{}(1-F),F{\textrightarrow}1-{\textbackslash}log F {\textbackslash}sim (1 - F), F {\textbackslash}rightarrow 1, we see that (1.2) holds if and only if limn{\textrightarrow}$\infty$n[1-F(anx+bn)]=-log$\Phi$(x).(1.5){\textbackslash}begin\{equation*\}{\textbackslash}tag\{1.5\}{\textbackslash}lim\_\{n {\textbackslash}rightarrow {\textbackslash}infty\} n{\textbackslash}lbrack 1 - F (a\_nx + b\_n){\textbackslash}rbrack = -{\textbackslash}log {\textbackslash}Phi(x).{\textbackslash}end\{equation*\}},
	language = {EN},
	number = {2},
	urldate = {2015-11-06},
	journal = {The Annals of Mathematical Statistics},
	author = {Berman, Simeon M.},
	month = jun,
	year = {1964},
	mrnumber = {MR161365},
	zmnumber = {0122.13503},
	pages = {502--516},
	file = {Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/XT6TM2Q6/DPubS.html:text/html}
}

@article{girshick_bayes_1952,
	title = {A {Bayes} {Approach} to a {Quality} {Control} {Model}},
	volume = {23},
	copyright = {Copyright {\textcopyright} 1952 Institute of Mathematical Statistics},
	issn = {0003-4851},
	url = {http://www.jstor.org/stable/2236405},
	abstract = {This paper deals with a class of statistical quality control procedures and continuous inspection procedures which are optimum for a specified income function and a production model which can only be in one of four states, two of which are states of repair, with known transition probabilities. The Markov process, generated by the model and the class of decision procedures, approaches a limiting distribution and the integral equations from which the optimum procedures can be derived are given.},
	number = {1},
	urldate = {2015-11-06},
	journal = {The Annals of Mathematical Statistics},
	author = {Girshick, M. A. and Rubin, Herman},
	month = mar,
	year = {1952},
	pages = {114--125},
	file = {Girshick_Rubin_1952_A Bayes Approach to a Quality Control Model.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/34MV9IIH/Girshick_Rubin_1952_A Bayes Approach to a Quality Control Model.pdf:application/pdf}
}

@article{duncan_economic_1956,
	title = {The {Economic} {Design} of {X} {Charts} {Used} to {Maintain} {Current} {Control} of a {Process}},
	volume = {51},
	issn = {0162-1459},
	url = {http://dx.doi.org/10.1080/01621459.1956.10501322},
	doi = {10.1080/01621459.1956.10501322},
	abstract = {This paper establishes a criterion that measures approximately the average net income of a process under surveillance of an X chart when the process is subject to random shifts in the process mean. The quality control rule assumed is that an assignable cause is looked for whenever a point falls outside the control limits. The criterion is for the case in which it is assumed that the process is not shut down while the search for the assignable cause is in progress, nor is the cost of adjustment or repair and the cost of bringing the process back into a state of control after the assignable cause is discovered charged to the control chart program. The paper shows how to determine the sample size, the interval between samples, and the control limits that will yield approximately maximum average net income. Numerical examples of optimum design are studied to see how variation in the various risk and cost factors affects the optimum. * The writer is greatly indebted to I. R. Savage and G. Greggory of Stanford University for their criticism and suggestions in preparation of this paper. The paper was completed while the writer was working at Stanford University under the auspices of the Office of Naval Research.},
	number = {274},
	urldate = {2015-11-06},
	journal = {Journal of the American Statistical Association},
	author = {Duncan, Acheson J.},
	month = jun,
	year = {1956},
	pages = {228--242},
	file = {Duncan_1956_The Economic Design of X Charts Used to Maintain Current Control of a Process.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/EMWMWXAN/Duncan_1956_The Economic Design of X Charts Used to Maintain Current Control of a Process.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/2FMCSHZ6/01621459.1956.html:text/html}
}

@book{hocking_analysis_1985,
	title = {The analysis of linear models},
	publisher = {Brooks/Cole Pub Co},
	author = {Hocking, Ronald R},
	year = {1985}
}

@book{greene_econometric_2003,
	title = {Econometric analysis},
	publisher = {Pearson Education India},
	author = {Greene, William H},
	year = {2003}
}

@book{fisher_design_1960,
	title = {The design of experiments},
	volume = {12},
	number = {6},
	publisher = {Oliver and Boyd Edinburgh},
	author = {Fisher, Sir Ronald Aylmer},
	year = {1960}
}

@book{mason_statistical_2003,
	title = {Statistical design and analysis of experiments: with applications to engineering and science},
	volume = {474},
	publisher = {John Wiley \& Sons},
	author = {Mason, Robert L and Gunst, Richard F and Hess, James L},
	year = {2003}
}

@book{rosenbaum_observational_2002,
	title = {Observational studies},
	publisher = {Springer},
	author = {Rosenbaum, Paul R},
	year = {2002}
}

@book{montgomery_design_2012,
	address = {Hoboken, NJ},
	edition = {8 edition},
	title = {Design and {Analysis} of {Experiments}},
	isbn = {978-1-118-14692-7},
	language = {English},
	publisher = {Wiley},
	author = {Montgomery, Douglas},
	month = apr,
	year = {2012}
}

@book{cox_theory_2000,
	title = {The {Theory} of the {Design} of {Experiments}},
	isbn = {978-1-4200-3583-4},
	abstract = {Why study the theory of experiment design? Although it can be useful to know about special designs for specific purposes, experience suggests that a particular design can rarely be used directly. It needs adaptation to accommodate the circumstances of the experiment. Successful designs depend upon adapting general theoretical principles to the special constraints of individual applications. Written for a general audience of researchers across the range of experimental disciplines, The Theory of the Design of Experiments presents the major topics associated with experiment design, focusing on the key concepts and the statistical structure of those concepts. The authors keep the level of mathematics elementary, for the most part, and downplay methods of data analysis. Their emphasis is firmly on design, but appendices offer self-contained reviews of algebra and some standard methods of analysis.From their development in association with agricultural field trials, through their adaptation to the physical sciences, industry, and medicine, the statistical aspects of the design of experiments have become well refined. In statistics courses of study, however, the design of experiments very often receives much less emphasis than methods of analysis. The Theory of the Design of Experiments fills this potential gap in the education of practicing statisticians, statistics students, and researchers in all fields.},
	language = {en},
	publisher = {CRC Press},
	author = {Cox, D. R. and Reid, Nancy},
	month = jun,
	year = {2000},
	keywords = {Mathematics / General, Mathematics / Probability \& Statistics / General, Science / Life Sciences / Biology}
}

@book{ge_multivariate_2012,
	title = {Multivariate {Statistical} {Process} {Control}: {Process} {Monitoring} {Methods} and {Applications}},
	isbn = {978-1-4471-4513-4},
	shorttitle = {Multivariate {Statistical} {Process} {Control}},
	abstract = {Given their key position in the process control industry, process monitoring techniques have been extensively investigated by industrial practitioners and academic control researchers. Multivariate statistical process control (MSPC) is one of the most popular data-based methods for process monitoring and is widely used in various industrial areas. Effective routines for process monitoring can help operators run industrial processes efficiently at the same time as maintaining high product quality. Multivariate Statistical Process Control reviews the developments and improvements that have been made to MSPC over the last decade, and goes on to propose a series of new MSPC-based approaches for complex process monitoring. These new methods are demonstrated in several case studies from the chemical, biological, and semiconductor industrial areas.  Control and process engineers, and academic researchers in the process monitoring, process control and fault detection and isolation (FDI) disciplines will be interested in this book. It can also be used to provide supplementary material and industrial insight for graduate and advanced undergraduate students, and graduate engineers. Advances in Industrial Control aims to report and encourage the transfer of technology in control engineering. The rapid development of control technology has an impact on all areas of the control discipline. The series offers an opportunity for researchers to present an extended exposition of new work in all aspects of industrial control.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Ge, Zhiqiang and Song, Zhihuan},
	month = nov,
	year = {2012},
	keywords = {Business \& Economics / Production \& Operations Management, Technology \& Engineering / Automation, Technology \& Engineering / Electrical, Technology \& Engineering / Industrial Technology}
}

@book{kotz_process_1993,
	title = {Process {Capability} {Indices}},
	isbn = {978-0-412-54380-7},
	abstract = {A solid, rigorous, yet comprehensible analysis of process capability indices, this work bridges the gap between theoretical statisticians and quality control practitioners, showing how an understanding of these indices can lead to process improvement.},
	language = {en},
	publisher = {CRC Press},
	author = {Kotz, Samuel and Johnson, Norman L.},
	month = jun,
	year = {1993},
	keywords = {Business \& Economics / Quality Control, Mathematics / Probability \& Statistics / General}
}

@book{wadsworth_modern_1986,
	title = {Modern {Methods} for {Quality} {Control} and {Improvement}},
	isbn = {978-0-471-84326-9},
	abstract = {This is a detailed presentation of modern quality control methods and systems, written by three researchers in the field. It strikes a balance between theoretical and practical aspects of quality control, and treats the traditional principles and techniques of statistical quality control and quality assurance using the most modern approaches. The book is designed for advanced undergraduate or graduate students in industrial engineering and management.},
	language = {en},
	publisher = {Wiley},
	author = {Wadsworth, Harrison M. and Stephens, Kenneth S. and Godfrey, A. Blanton},
	year = {1986}
}

@book{angela_m._dean_design_2000,
	address = {New York},
	edition = {Corrected edition},
	title = {Design and {Analysis} of {Experiments}},
	isbn = {978-0-387-98561-9},
	language = {English},
	publisher = {Springer},
	author = {{Angela M. Dean} and {Daniel Voss}},
	month = dec,
	year = {2000}
}

@book{geoffrey_m._clarke_introduction_2010,
	address = {New York, N.Y.},
	edition = {1 edition},
	title = {Introduction to the {Design} and {Analysis} of {Experiments}},
	isbn = {978-0-470-71107-1},
	language = {English},
	publisher = {Wiley},
	author = {{Geoffrey M. Clarke} and {Robert E. Kempson}},
	month = may,
	year = {2010}
}

@book{everitt_cambridge_2010,
	address = {Cambridge, UK ; New York},
	edition = {4 edition},
	title = {The {Cambridge} {Dictionary} of {Statistics}},
	isbn = {978-0-521-76699-9},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Everitt, B. S. and Skrondal, Anders},
	month = oct,
	year = {2010}
}

@book{hill_first_1986,
	title = {A {First} {Course} in {Coding} {Theory}},
	isbn = {978-0-19-853803-5},
	abstract = {Algebraic coding theory is a new and rapidly developing subject, popular for its many practical applications and for its fascinatingly rich mathematical structure. This book provides an elementary yet rigorous introduction to the theory of error-correcting codes. Based on courses given by the author over several years to advanced undergraduates and first-year graduated students, this guide includes a large number of exercises, all with solutions, making the book highly suitable for individual study.},
	language = {en},
	publisher = {Clarendon Press},
	author = {Hill, Raymond},
	year = {1986},
	keywords = {Technology \& Engineering / Agriculture / General}
}

@book{hedayat_orthogonal_1999,
	title = {Orthogonal {Arrays}: {Theory} and {Applications}},
	isbn = {978-0-387-98766-8},
	shorttitle = {Orthogonal {Arrays}},
	abstract = {This is the first book on the subject since its introduction more than fifty years ago, and it can be used as a graduate text or as a reference work. It features all of the key results, many very useful tables, and a large number of research problems. The book will be of interest to those interested in one of the most fascinating areas of discrete mathematics, connected to statistics and coding theory, with applications to computer science and cryptography. It will be useful for anyone who is running experiments, whether in a chemistry lab or a manufacturing plant (trying to make those alloys stronger), or in agricultural or medical research. Sam Hedayat is Professor of Statistics and Senior Scholar in the Department of Mathematics, Statistics, and Computer Science, University of Illinois, Chicago. Neil J.A. Sloane is with AT\&T Bell Labs (now AT\&T Labs). John Stufken is Professor Statistics at Iowa State University.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Hedayat, A. S. and Sloane, N. J. A. and Stufken, John},
	month = jun,
	year = {1999},
	keywords = {Mathematics / Group Theory, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{santner_design_2013,
	title = {The {Design} and {Analysis} of {Computer} {Experiments}},
	isbn = {978-1-4757-3799-8},
	abstract = {In the past 15 to 20 years, the computer has become a popular tool for exploring the relationship between a measured response and factors thought to affect the response. In many cases, scientific theories exist that implicitly relate the response to the factors by means of systems of mathematical equations. There also exist numerical methods for accurately solving such equations and appropriate computer hardware and software to implement these methods. In many engineering applications, for example, the relationship is described by a dynamical system and the numerical method is a finite element code. In such situations, these numerical methods allow one to produce computer code that can generate the response corresponding to any given set of values of the factors. This allows one to conduct an "experiment" (called a "computer experiment") to explore the relationship between the response and the factors using the code. Indeed, in some cases computer experimentation is feasible when a properly designed physical experiment (the gold standard for establishing cause and effect) is impossible. For example, the number of input variables may be too large to consider performing a physical experiment or it may simply be economically prohibitive to run an experiment on the scale required to gather sufficient information to answer a particular research question. This book describes methods for designing and analyzing experiments conducted using computer code in lieu of a physical experiment. It discusses how to select the values of the factors at which to run the code (the design of the computer experiment) in light of the research objectives of the experimenter. It also provides techniques for analyzing the resulting data so as to achieve these research goals. It illustrates these methods with code that is available to the reader at},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Santner, Thomas J. and Williams, Brian J. and Notz, William I.},
	month = mar,
	year = {2013},
	keywords = {Computers / Computer Simulation, Computers / Desktop Applications / Design \& Graphics, Mathematics / Applied, Mathematics / Counting \& Numeration, Mathematics / Numerical Analysis, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{aven_stochastic_1999,
	title = {Stochastic models in reliability},
	url = {http://link.springer.com/content/pdf/10.1007/978-1-4614-7894-2.pdf},
	urldate = {2015-11-15},
	publisher = {Springer},
	author = {Aven, Terje and Jensen, Uwe},
	year = {1999},
	file = {Aven_Jensen_1999_Stochastic models in reliability.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/WQ86ZUZJ/Aven_Jensen_1999_Stochastic models in reliability.pdf:application/pdf}
}

@article{nadarajah_bathtub-shaped_2008,
	title = {Bathtub-shaped failure rate functions},
	volume = {43},
	issn = {0033-5177, 1573-7845},
	url = {http://link.springer.com/article/10.1007/s11135-007-9152-9},
	doi = {10.1007/s11135-007-9152-9},
	abstract = {The failure rate function is an important quantity characterizing life phenomena. Ideally, one would expect this function to exhibit a bathtub shape. In this paper, a comprehensive review of the known distributions that exhibit this shape is provided. Over 17 such distributions are identified. This review is especially important because almost all of the commonly known distributions in statistics do not exhibit the bathtub shape. Furthermore, it could serve as an important reference and encourage developments of further distributions that exhibit a bathtub shape.},
	language = {en},
	number = {5},
	urldate = {2015-11-15},
	journal = {Quality \& Quantity},
	author = {Nadarajah, Saralees},
	month = jan,
	year = {2008},
	keywords = {Bathtub shape, Failure rate function, Methodology of the Social Sciences, Social Sciences, general, Weibull distribution},
	pages = {855--863},
	file = {Nadarajah_2008_Bathtub-shaped failure rate functions.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/6SSS96GZ/Nadarajah_2008_Bathtub-shaped failure rate functions.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TWM29DJK/s11135-007-9152-9.html:text/html}
}

@book{nahmias_production_2015,
	title = {Production and {Operations} {Analysis}: {Seventh} {Edition}},
	isbn = {978-1-4786-2824-8},
	shorttitle = {Production and {Operations} {Analysis}},
	abstract = {The Seventh Edition of Production and Operations Analysis builds a  solid foundation for beginning students of production and operations  management. Continuing a long tradition of excellence, Nahmias and Olsen  bring decades of combined experience to craft the most clear and  up-to-date resource available. The authors{\textquoteright} thorough updates include  incorporation of current technology that improves the effectiveness of  production processes, additional qualitative sections, and new material  on service operations management and servicization. Bolstered by copious  examples and problems, each chapter stands alone, allowing instructors  to tailor the material to their specific needs. The text is essential  reading for learning how to better analyze and improve on all facets of  operations.},
	language = {en},
	publisher = {Waveland Press},
	author = {Nahmias, Steven and Olsen, Tava Lennon},
	month = jan,
	year = {2015},
	keywords = {Business \& Economics / Production \& Operations Management, Technology \& Engineering / Industrial Engineering, Technology \& Engineering / Operations Research}
}

@article{bagnoli_log-concave_2005,
	title = {Log-{Concave} {Probability} and {Its} {Applications}},
	volume = {26},
	issn = {0938-2259},
	url = {http://www.jstor.org/stable/25055959},
	abstract = {In many applications, assumptions about the log-concavity of a probability distribution allow just enough special structure to yield a workable theory. This paper catalogs a series of theorems relating log-concavity and/or log-convexity of probability density functions, distribution functions, reliability functions, and their integrals. We list a large number of commonly-used probability distributions and report the log-concavity or log-convexity of their density functions and their integrals. We also discuss a variety of applications of log-concavity that have appeared in the literature.},
	number = {2},
	urldate = {2015-11-15},
	journal = {Economic Theory},
	author = {Bagnoli, Mark and Bergstrom, Ted},
	year = {2005},
	pages = {445--469},
	file = {Bagnoli_Bergstrom_2005_Log-Concave Probability and Its Applications.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/G3EB3NPG/Bagnoli_Bergstrom_2005_Log-Concave Probability and Its Applications.pdf:application/pdf}
}

@book{cox_analysis_1984,
	title = {Analysis of {Survival} {Data}},
	isbn = {978-0-412-24490-2},
	abstract = {This monograph contains many ideas on the analysis of survival data to present a comprehensive account of the field. The value of survival analysis is not confined to medical statistics, where the benefit of the analysis of data on such factors as life expectancy and duration of periods of freedom from symptoms of a disease as related to a treatment applied individual histories and so on, is obvious. The techniques also find important applications in industrial life testing and a range of subjects from physics to econometrics. In the eleven chapters of the book the methods and applications of are discussed and illustrated by examples.},
	language = {en},
	publisher = {CRC Press},
	author = {Cox, D. R. and Oakes, David},
	month = jun,
	year = {1984},
	keywords = {Mathematics / Probability \& Statistics / General, Science / Life Sciences / Biology}
}

@article{laird_covariance_1981,
	title = {Covariance {Analysis} of {Censored} {Survival} {Data} {Using} {Log}-{Linear} {Analysis} {Tech}},
	author = {Laird, Nan and Oliver, Donald},
	year = {1981}
}

@article{holford_analysis_1980,
	title = {The analysis of rates and of survivorship using log-linear models},
	url = {http://www.jstor.org/stable/2529982},
	urldate = {2015-11-16},
	journal = {Biometrics},
	author = {Holford, Theodore R.},
	year = {1980},
	pages = {299--305}
}

@article{kowalski_how_2003,
	title = {How to recognize a split-plot experiment},
	volume = {36},
	url = {http://minitab.com.au/uploadedFiles/Content/News/Published_Articles/recognize_split_plot_experiment.pdf},
	number = {11},
	urldate = {2015-11-17},
	journal = {Quality progress},
	author = {Kowalski, Scott M. and Potcner, Kevin J.},
	year = {2003},
	pages = {60--66},
	file = {Kowalski_Potcner_2003_How to recognize a split-plot experiment.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/EAVIS2HI/Kowalski_Potcner_2003_How to recognize a split-plot experiment.pdf:application/pdf}
}

@book{pukelsheim_optimal_1993,
	title = {Optimal {Design} of {Experiments}},
	isbn = {978-0-89871-910-9},
	abstract = {Optimal Design of Experiments offers a rare blend of linear algebra, convex analysis, and statistics. The optimal design for statistical experiments is first formulated as a concave matrix optimization problem. Using tools from convex analysis, the problem is solved generally for a wide class of optimality criteria such as D-, A-, or E-optimality. The book then offers a complementary approach that calls for the study of the symmetry properties of the design problem, exploiting such notions as matrix majorization and the Kiefer information matrix ordering. The results are illustrated with optimal designs for polynomial fit models, Bayes designs, balanced incomplete block designs, exchangeable designs on the cube, rotatable designs on the sphere, and many other examples. Since the book\&\#39;s initial publication in 1993, readers have used its methods to derive optimal designs on the circle, optimal mixture designs, and optimal designs in other statistical models. Using local linearization techniques, the methods described in the book prove useful even for nonlinear cases, in identifying practical designs of experiments. Audience: anyone involved in planning statistical experiments, including mathematical statisticians, applied statisticians, and mathematicians interested in matrix optimization problems.},
	language = {en},
	publisher = {SIAM},
	author = {Pukelsheim, Friedrich},
	year = {1993}
}

@book{box_statistics_1978,
	title = {Statistics for experimenters: an introduction to design, data analysis, and model building},
	isbn = {978-0-471-09315-2},
	shorttitle = {Statistics for experimenters},
	abstract = {Introduces the philosophy of experimentation and the part that statistics play in experimentation. Emphasizes the need to develop a capability for ``statistical thinking'' by using examples drawn from actual case studies.},
	language = {en},
	publisher = {Wiley},
	author = {Box, George E. P. and Hunter, William Gordon and Hunter, J. Stuart},
	month = jul,
	year = {1978},
	keywords = {Analisis de varianza, Analisis multivariado, analysis of variance, Dise{\k o} de experimentos, Experimental design, Mathematics / Probability \& Statistics / General, Science / Research \& Methodology, Technology \& Engineering / Engineering (General)}
}

@book{kalbfleisch_statistical_2002,
	title = {The {Statistical} {Analysis} of {Failure} {Time} {Data}},
	isbn = {978-0-471-36357-6},
	abstract = {Now entering its fourth edition, the market-leading Handbook of MRI Technique has been fully revised and updated to incorporate new technologies and developments essential to good practice. Written specifically for technologists and highly illustrated, it guides the uninitiated through scanning techniques and helps more experienced technologists to improve image quality. The first part of the book considers the main aspects of theory that relate to scanning and also includes practical tips on gating, equipment use, patient care and safety, and information on contrast media. The second half provides step-by-step instruction for examining each anatomical area, beginning with a basic anatomy section followed by sections on indications, patient positioning, equipment, artefacts and tips on optimizing image quality.  Written by an international team of technologists from the United States, United Kingdom and Europe Suitable for users for all types of MRI systems Now includes key points throughout for quick reference Companion website at www.wiley.com/go/westbrook/mritechnique with self-assessment and image flashcards  Handbook of MRI Technique continues to be the ideal support both for radiographers new to MRI and for regular users looking for information on alternative techniques and suggestions on protocol modifications.},
	language = {en},
	publisher = {Wiley},
	author = {Kalbfleisch, John D. and Prentice, Ross L.},
	month = sep,
	year = {2002},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{klein_survival_2005,
	title = {Survival {Analysis}: {Techniques} for {Censored} and {Truncated} {Data}},
	isbn = {978-0-387-95399-1},
	shorttitle = {Survival {Analysis}},
	abstract = {Applied statisticians in many fields frequently analyze time-to-event data. While the statistical tools presented in this book are applicable to data from medicine, biology, public health, epidemiology, engineering, economics and demography, the focus here is on applications of the techniques to biology and medicine. The analysis of survival experiments is complicated by issues of censoring and truncation. The use of counting process methodology has allowed for substantial advances in the statistical theory to account for censoring and truncation in survival experiments. This book makes these complex techniques accessible to applied researchers without the advanced mathematical background. The authors present the essentials of these techniques, as well as classical techniques not based on counting processes, and apply them to data. The second edition contains some new material as well as solutions to the odd-numbered revised exercises. New material consists of a discussion of summary statistics for competing risks probabilities in Chapter 2 and the estimation process for these probabilities in Chapter 4. A new section on tests of the equality of survival curves at a fixed point in time is added in Chapter 7. In Chapter 8 an expanded discussion is presented on how to code covariates and a new section on discretizing a continuous covariate is added. A new section on Lin and Ying's additive hazards regression model is presented in Chapter 10. We now proceed to a general discussion of the usefulness of this book incorporating the new material with that of the first edition.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Klein, John P. and Moeschberger, Melvin L.},
	month = mar,
	year = {2005},
	keywords = {Business \& Economics / Statistics, Mathematics / Probability \& Statistics / General, Medical / Biostatistics, Medical / Epidemiology, Medical / General, Social Science / Methodology, Social Science / Research}
}

@book{venables_modern_2002,
	address = {New York, NY},
	series = {Statistics and {Computing}},
	title = {Modern {Applied} {Statistics} with {S}},
	isbn = {978-1-4419-3008-8 978-0-387-21706-2},
	url = {http://link.springer.com/10.1007/978-0-387-21706-2},
	urldate = {2015-11-18},
	publisher = {Springer New York},
	author = {Venables, W. N. and Ripley, B. D.},
	editor = {Chambers, J. and Eddy, W. and H{\"a}rdle, W. and Sheather, S. and Tierney, L.},
	year = {2002}
}

@article{dorfman_detection_1943,
	title = {The {Detection} of {Defective} {Members} of {Large} {Populations}},
	volume = {14},
	issn = {0003-4851, 2168-8990},
	url = {http://projecteuclid.org/euclid.aoms/1177731363},
	doi = {10.1214/aoms/1177731363},
	abstract = {Project Euclid - mathematics and statistics online},
	language = {EN},
	number = {4},
	urldate = {2015-12-05},
	journal = {The Annals of Mathematical Statistics},
	author = {Dorfman, Robert},
	month = dec,
	year = {1943},
	pages = {436--440},
	file = {Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/JDCRH86H/1177731363.html:text/html}
}

@article{goeman_multiple_2011,
	title = {Multiple {Testing} for {Exploratory} {Research}},
	volume = {26},
	issn = {0883-4237},
	url = {http://www.jstor.org/stable/23208743},
	abstract = {Motivated by the practice of exploratory research, we formulate an approach to multiple testing that reverses the conventional roles of the user and the multiple testing procedure. Traditionally, the user chooses the error criterion, and the procedure the resulting rejected set. Instead, we propose to let the user choose the rejected set freely, and to let the multiple testing procedure return a confidence statement on the number of false rejections incurred. In our approach, such confidence statements are simultaneous for all choices of the rejected set, so that post hoc selection of the rejected set does not compromise their validity. The proposed reversal of roles requires nothing more than a review of the familiar closed testing procedure, but with a focus on the non-consonant rejections that this procedure makes. We suggest several shortcuts to avoid the computational problems associated with closed testing.},
	number = {4},
	urldate = {2016-02-14},
	journal = {Statistical Science},
	author = {Goeman, Jelle J. and Solari, Aldo},
	year = {2011},
	pages = {584--597},
	file = {Goeman_Solari_2011_Multiple Testing for Exploratory Research.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ZIJ568RA/Goeman_Solari_2011_Multiple Testing for Exploratory Research.pdf:application/pdf}
}

@book{john_statistical_1971,
	title = {Statistical design and analysis of experiments},
	url = {http://epubs.siam.org/doi/pdf/10.1137/1.9781611971149.fm},
	urldate = {2015-12-27},
	publisher = {SIAM},
	author = {John, Peter William Meredith},
	year = {1971},
	file = {Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/36QS4XEI/1.9781611971149.html:text/html}
}

@article{liu_control_1995,
	title = {Control {Charts} for {Multivariate} {Processes}},
	volume = {90},
	issn = {0162-1459},
	url = {http://www.jstor.org/stable/2291529},
	doi = {10.2307/2291529},
	abstract = {This article uses the concept of data depth to introduce several new control charts for monitoring processes of multivariate quality measurements. For any dimension of the measurements, these charts are in the form of two-dimensional graphs that can be visualized and interpreted just as easily as the well-known univariate X, X?, and CUSUM charts. Moreover, they have several significant advantages. First, they can detect simultaneously the location shift and scale increase of the process, unlike the existing methods, which can detect only the location shift. Second, their construction is completely nonparametric; in particular, it does not require the assumption of normality for the quality distribution, which is needed in standard approaches such as the $\chi$2 and Hotelling's T2 charts. Thus these new charts generalize the principle of control charts to multivariate settings and apply to a much broader class of quality distributions.},
	number = {432},
	urldate = {2016-04-05},
	journal = {Journal of the American Statistical Association},
	author = {Liu, Regina Y.},
	year = {1995},
	pages = {1380--1387}
}

@article{li_using_2012,
	title = {Using p values to design statistical process control charts},
	volume = {54},
	issn = {0932-5026, 1613-9798},
	url = {http://link.springer.com/article/10.1007/s00362-012-0447-0},
	doi = {10.1007/s00362-012-0447-0},
	abstract = {Conventional Phase II statistical process control (SPC) charts are designed using control limits; a chart gives a signal of process distributional shift when its charting statistic exceeds a properly chosen control limit. To do so, we only know whether a chart is out-of-control at a given time. It is therefore not informative enough about the likelihood of a potential distributional shift. In this paper, we suggest designing the SPC charts using p values. By this approach, at each time point of Phase II process monitoring, the p value of the observed charting statistic is computed, under the assumption that the process is in-control. If the p value is less than a pre-specified significance level, then a signal of distributional shift is delivered. This p value approach has several benefits, compared to the conventional design using control limits. First, after a signal of distributional shift is delivered, we could know how strong the signal is. Second, even when the p value at a given time point is larger than the significance level, it still provides us useful information about how stable the process performs at that time point. The second benefit is especially useful when we adopt a variable sampling scheme, by which the sampling time can be longer when we have more evidence that the process runs stably, supported by a larger p value. To demonstrate the p value approach, we consider univariate process monitoring by cumulative sum control charts in various cases.},
	language = {en},
	number = {2},
	urldate = {2016-04-04},
	journal = {Statistical Papers},
	author = {Li, Zhonghua and Qiu, Peihua and Chatterjee, Snigdhansu and Wang, Zhaojun},
	month = apr,
	year = {2012},
	keywords = {bootstrap, Cumulative sum control charts, Economic Theory, Operations Research/Decision Theory, Probability Theory and Stochastic Processes, Process monitoring, Self-starting, Statistics for Business/Economics/Mathematical Finance/Insurance, Variable sampling},
	pages = {523--539},
	file = {Li et al_2012_Using p values to design statistical process control charts.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/35EHAWRJ/Li et al_2012_Using p values to design statistical process control charts.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TJWMRMI2/s00362-012-0447-0.html:text/html}
}

@misc{_nist/sematech_????,
	title = {{NIST}/{SEMATECH} e-{Handbook} of {Statistical} {Methods}},
	url = {http://www.itl.nist.gov/div898/handbook/index.htm},
	urldate = {2016-04-04},
	file = {NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/9552ZZPS/index.html:text/html;NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/PNNFE43M/index.html:text/html;NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/7SPXIWCS/index.html:text/html;NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/N27E6HVK/index.html:text/html}
}