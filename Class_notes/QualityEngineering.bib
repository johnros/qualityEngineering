
@article{wassmer_basic_2000,
  title = {Basic Concepts of Group Sequential and Adaptive Group Sequential Test Procedures},
  volume = {41},
  doi = {10.1007/BF02925923},
  abstract = {Abstract  Based on the concept of repeated significance tests, an empirical study may be planned in subsequent stages. Group sequential
test procedures offer the possibility of performing the study with a fixed number of observations per stage. At least, the
number of observations must be chosen independently of the observed data. In adaptive group sequential test procedures, the
number of observations can be changed during the course of the study using all results observed so far. In this article, the
basic concepts of these two designs are reviewed. Recent developments in adaptive designs are outlined and potential fields
of application are given.},
  timestamp = {2009-08-08T14:59:23Z},
  number = {3},
  urldate = {2009-08-08},
  journal = {Statistical Papers},
  author = {Wassmer, Gernot},
  month = jul,
  year = {2000},
  pages = {253--279},
  file = {Wassmer_2000_Basic concepts of group sequential and adaptive group sequential test procedures.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/PG6PMQG2/Wassmer_2000_Basic concepts of group sequential and adaptive group sequential test procedures.pdf:application/pdf;SpringerLink Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/7GZH98B3/317785344unk3674.html:text/html}
}

@book{petersen_matrix_2006,
  title = {The Matrix Cookbook},
  timestamp = {2010-01-04T16:22:56Z},
  publisher = {{Citeseer}},
  author = {Petersen, K. B and Pedersen, M. S},
  year = {2006},
  keywords = {Mathematics}
}

@article{berchenko_modeling_2013,
  title = {Modeling and {{Analysing Respondent Driven Sampling}} as a {{Counting Process}}},
  abstract = {Respondent driven sampling (RDS) is an approach to sampling design utilizing the networks of social relationships that connect members of the target population to facilitate sampling by chain referral methods. Although this leads to biased sampling (such as over-sampling participants with many acquaintances), most RDS studies typically measure each participant's degree, and under the fundamental RDS assumption (that the probability to sample an individual is proportional to his degree) use inverse-probability weighting in an attempt to correct for this bias. However, this assumption is tenuous at best, and should be avoided. Here we suggest a completely novel approach for inference in RDS which compensates for such problems by using a rich source of information that is usually ignored - the precise timing of recruitment. Our new approach, adapting methods developed for inference in epidemic processes, also allows us to develop new estimators for properties such as the prevalence of a disease and the total population size, as well as to test the assumption of recruitment proportional to degree. We find these estimators asymptotically consistent and normally distributed. This new approach thus has the potential to greatly improve the utility of data collected using RDS.},
  timestamp = {2013-04-24T21:08:33Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1304.3505},
  urldate = {2013-04-24},
  journal = {arXiv:1304.3505},
  author = {Berchenko, Yakir and Rosenblatt, Jonathan and Frost, Simon D. W.},
  month = apr,
  year = {2013},
  file = {Berchenko et al_2013_Modeling and Analysing Respondent Driven Sampling as a Counting Process.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TXPS6475/Berchenko et al_2013_Modeling and Analysing Respondent Driven Sampling as a Counting Process.pdf:application/pdf;arXiv.org Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZT26ABBZ/1304.html:text/html}
}

@article{donoho_higher_2004,
  title = {Higher Criticism for Detecting Sparse Heterogeneous Mixtures},
  volume = {32},
  issn = {0090-5364},
  doi = {10.1214/009053604000000265},
  timestamp = {2014-07-29T19:37:53Z},
  number = {3},
  journal = {Annals of Statistics},
  author = {Donoho, D. and Jin, J. S.},
  month = jun,
  year = {2004},
  note = {WOS:000221981400005},
  pages = {962--994},
  file = {Donoho_Jin_2004_Higher criticism for detecting sparse heterogeneous mixtures.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/V9WM9RC5/Donoho_Jin_2004_Higher criticism for detecting sparse heterogeneous mixtures.pdf:application/pdf}
}

@article{jin_cosmological_2005,
  title = {Cosmological Non-{{Gaussian Signature Detection}}: {{Comparing Performance}} of {{Different Statistical Tests}}},
  volume = {2005},
  issn = {1110-8657},
  shorttitle = {Cosmological Non-{{Gaussian Signature Detection}}},
  doi = {10.1155/ASP.2005.2470},
  timestamp = {2014-09-01T12:33:16Z},
  urldate = {2014-09-01},
  journal = {EURASIP J. Appl. Signal Process.},
  author = {Jin, J. and Starck, J.-L. and Donoho, D. L. and Aghanim, N. and Forni, O.},
  month = jan,
  year = {2005},
  keywords = {cosmological microwave background,cosmology,curvelet,multiscale method,non-Gaussianity detection,wavelet},
  pages = {2470--2485},
  file = {Jin et al_2005_Cosmological non-Gaussian Signature Detection.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/8QDFXAZJ/Jin et al_2005_Cosmological non-Gaussian Signature Detection.pdf:application/pdf}
}

@article{marc_vandemeulebroecke_group_2008,
  title = {Group {{Sequential}} and {{Adaptive Designs}} - {{A Review}} of {{Basic Concepts}} and {{Points}} of {{Discussion}}},
  volume = {50},
  doi = {10.1002/bimj.200710436},
  abstract = {In recent times, group sequential and adaptive designs for clinical trials have attracted great attention from industry, academia and regulatory authorities. These designs allow analyses on accumulating data - as opposed to classical, ldquofixed-samplerdquo statistics. The rapid development of a great variety of statistical procedures is accompanied by a lively debate on their potential merits and shortcomings. The purpose of this review article is to ease orientation in both respects. First, we provide a concise overview of the essential technical concepts, with special emphasis on their interrelationships. Second, we give a structured review of the current controversial discussion on practical issues, opportunities and challenges of these new designs. (\textcopyright{} 2008 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
  timestamp = {2014-09-09T06:57:23Z},
  number = {4},
  urldate = {2009-08-08},
  journal = {Biometrical Journal},
  author = {{Marc Vandemeulebroecke}},
  year = {2008},
  keywords = {Adaptive design,Adaptive Designs,Combination test,Conditional error function,DOE,Flexible design,Group sequential design,Interim analysis,Review,Sequential analysis,Spending function,Statistics,Trial integrity,Trial validity},
  pages = {541--557},
  file = {Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/QZ9UZ5BP/Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:application/pdf;Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/VTFZ693X/Marc Vandemeulebroecke_2008_Group Sequential and Adaptive Designs - A Review of Basic Concepts and Points.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/FI9J8SUC/abstract\;jsessionid=524233E08375CE22D0BE5CE6254ADA07.html:text/html}
}

@book{meyer_matrix_2001,
  address = {Philadelphia},
  edition = {Har/Cdr edition},
  title = {Matrix {{Analysis}} and {{Applied Linear Algebra Book}} and {{Solutions Manual}}},
  isbn = {978-0-89871-454-8},
  abstract = {This book avoids the traditional definition-theorem-proof format; instead a fresh approach introduces a variety of problems and examples all in a clear and informal style. The in-depth focus on applications separates this book from others, and helps students to see how linear algebra can be applied to real-life situations. Some of the more contemporary topics of applied linear algebra are included here which are not normally found in undergraduate textbooks. Theoretical developments are always accompanied with detailed examples, and each section ends with a number of exercises from which students can gain further insight. Moreover, the inclusion of historical information provides personal insights into the mathematicians who developed this subject. The textbook contains numerous examples and exercises, historical notes, and comments on numerical performance and the possible pitfalls of algorithms. Solutions to all of the exercises are provided, as well as a CD-ROM containing a searchable copy of the textbook.},
  language = {English},
  timestamp = {2015-04-26T13:18:17Z},
  publisher = {{SIAM: Society for Industrial and Applied Mathematics}},
  author = {Meyer, Carl D.},
  month = feb,
  year = {2001}
}

@book{anderson_introduction_2003,
  address = {Hoboken, NJ},
  edition = {3 edition},
  title = {An {{Introduction}} to {{Multivariate Statistical Analysis}}},
  isbn = {978-0-471-36091-9},
  abstract = {Perfected over three editions and more than forty years, this field- and classroom-tested reference: * Uses the method of maximum likelihood to a large extent to ensure reasonable, and in some cases optimal procedures. * Treats all the basic and important topics in multivariate statistics. * Adds two new chapters, along with a number of new sections. * Provides the most methodical, up-to-date information on MV statistics available.},
  language = {English},
  timestamp = {2015-05-04T06:37:32Z},
  publisher = {{Wiley-Interscience}},
  author = {Anderson, T. W.},
  month = jul,
  year = {2003}
}

@article{bai_effect_1996,
  title = {Effect of High Dimension: By an Example of a Two Sample Problem},
  volume = {6},
  shorttitle = {Effect of High Dimension},
  timestamp = {2015-05-27T15:12:46Z},
  number = {2},
  urldate = {2015-05-27},
  journal = {Statistica Sinica},
  author = {Bai, Zhidong D. and Saranadasa, Hewa},
  year = {1996},
  pages = {311--329},
  file = {Bai_Saranadasa_1996_Effect of high dimension.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/CTHV3HMB/Bai_Saranadasa_1996_Effect of high dimension.pdf:application/pdf}
}

@article{srivastava_two_2013,
  title = {A Two Sample Test in High Dimensional Data},
  volume = {114},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2012.08.014},
  abstract = {In this paper we propose a test for testing the equality of the mean vectors of two groups with unequal covariance matrices based on N 1 and N 2 independently distributed p -dimensional observation vectors. It will be assumed that N 1 observation vectors from the first group are normally distributed with mean vector $\mu$ 1 and covariance matrix $\Sigma$ 1 . Similarly, the N 2 observation vectors from the second group are normally distributed with mean vector $\mu$ 2 and covariance matrix $\Sigma$ 2 . We propose a test for testing the hypothesis that $\mu$ 1 = $\mu$ 2 . This test is invariant under the group of p \texttimes{} p nonsingular diagonal matrices. The asymptotic distribution is obtained as ( N 1 , N 2 , p ) $\rightarrow$ $\infty$ and N 1 / ( N 1 + N 2 ) $\rightarrow$ k $\in$ ( 0 , 1 ) but N 1 / p and N 2 / p may go to zero or infinity. It is compared with a recently proposed non-invariant test. It is shown that the proposed test performs the best.},
  timestamp = {2015-05-31T14:04:32Z},
  urldate = {2015-05-31},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S. and Katayama, Shota and Kano, Yutaka},
  month = feb,
  year = {2013},
  keywords = {Asymptotic theory,Behrens–Fisher problem,High-dimensional data,Hypothesis testing},
  pages = {349--358},
  file = {Srivastava et al_2013_A two sample test in high dimensional data.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/HITJM4F3/Srivastava et al_2013_A two sample test in high dimensional data.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/T8KIS5U9/S0047259X12002126.html:text/html}
}

@article{srivastava_test_2009,
  title = {A Test for the Mean Vector with Fewer Observations than the Dimension under Non-Normality},
  volume = {100},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2008.06.006},
  abstract = {In this article, we consider the problem of testing that the mean vector $\mu$ = 0 in the model x j = $\mu$ + C z j , j = 1 , \ldots{} , N , where z j are random p -vectors, z j = ( z i j , \ldots{} , z p j ) ${'}$ and z i j are independently and identically distributed with finite four moments, i = 1 , \ldots{} , p , j = 1 , \ldots{} , N ; that is x i need not be normally distributed. We shall assume that C is a p \texttimes{} p non-singular matrix, and there are fewer observations than the dimension, N $\leq$ p . We consider the test statistic T = [ N x \textasciimacron{} ${'}$ D s - 1 x \textasciimacron{} - n p / ( n - 2 ) ] / [ 2 tr R 2 - p 2 / n ] 1 2 , where x \textasciimacron{} is the sample mean vector, S = ( s i j ) is the sample covariance matrix, D S = diag ( s 11 , \ldots{} , s p p ) , R = D s - 1 2 S D s - 1 2 and n = N - 1 . The asymptotic null and non-null distributions of the test statistic T are derived.},
  timestamp = {2015-05-31T14:24:26Z},
  number = {3},
  urldate = {2015-05-31},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S.},
  month = mar,
  year = {2009},
  keywords = {62H10,62H15,Asymptotic null and non-null distribution,Fewer observations,High dimension,Non-normality,Testing mean vector},
  pages = {518--532},
  file = {Srivastava_2009_A test for the mean vector with fewer observations than the dimension under.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/WV4NJV6T/Srivastava_2009_A test for the mean vector with fewer observations than the dimension under.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/7CIBT3PK/S0047259X08001528.html:text/html}
}

@article{srivastava_multivariate_2006,
  series = {Special Issue dedicated to Prof. Fujikoshi},
  title = {Multivariate Analysis of Variance with Fewer Observations than the Dimension},
  volume = {97},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2005.08.010},
  abstract = {In this article, we consider the problem of testing a linear hypothesis in a multivariate linear regression model which includes the case of testing the equality of mean vectors of several multivariate normal populations with common covariance matrix $\Sigma$ , the so-called multivariate analysis of variance or MANOVA problem. However, we have fewer observations than the dimension of the random vectors. Two tests are proposed and their asymptotic distributions under the hypothesis as well as under the alternatives are given under some mild conditions. A theoretical comparison of these powers is made.},
  timestamp = {2015-06-01T11:24:20Z},
  number = {9},
  urldate = {2015-05-31},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S. and Fujikoshi, Yasunori},
  month = oct,
  year = {2006},
  keywords = {Distribution of test statistics,DNA microarray data,Fewer observations than dimension,Moore–Penrose inverse,Multivariate analysis of variance,Singular Wishart},
  pages = {1927--1940},
  file = {Srivastava_Fujikoshi_2006_Multivariate analysis of variance with fewer observations than the dimension.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/EWAGCUD5/Srivastava_Fujikoshi_2006_Multivariate analysis of variance with fewer observations than the dimension.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZFRXZHMG/S0047259X06000777.html:text/html}
}

@article{srivastava_test_2008,
  title = {A Test for the Mean Vector with Fewer Observations than the Dimension},
  volume = {99},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2006.11.002},
  abstract = {In this paper, we consider a test for the mean vector of independent and identically distributed multivariate normal random vectors where the dimension p is larger than or equal to the number of observations N. This test is invariant under scalar transformations of each component of the random vector. Theories and simulation results show that the proposed test is superior to other two tests available in the literature. Interest in such significance test for high-dimensional data is motivated by DNA microarrays. However, the methodology is valid for any application which involves high-dimensional data.},
  timestamp = {2015-06-01T11:56:51Z},
  number = {3},
  urldate = {2015-06-01},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S. and Du, Meng},
  month = mar,
  year = {2008},
  keywords = {Asymptotic distribution,DNA microarray,Multivariate normal,Power comparison,Significance test},
  pages = {386--402},
  file = {Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/7GXHRAJV/Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZM7JH2QS/S0047259X06001990.html:text/html}
}

@article{fuchs_multivariate_1994,
  title = {Multivariate {{Profile Charts}} for {{Statistical Process Control}}},
  volume = {36},
  issn = {0040-1706},
  doi = {10.1080/00401706.1994.10485765},
  abstract = {The multivariate profile (MP) chart is a new control chart for simultaneous display of univariate and multivariate statistics. It is designed to analyze and display extended structures of statistical process control data for various cases of grouping, reference distribution, and use of nominal specifications. For each group of observations, the scaled deviations from reference values are portrayed together as a modified profile plot symbol. The vertical location of the symbol is determined by the multivariate distance of the vector of means from the reference values. The graphical display in the MP chart enjoys improved visual characteristics as compared with previously suggested methods. Moreover, the perceptual tasks required by the use of the MP chart provide higher accuracy in retrieving the quantitative information. This graphical display is used to display other combined univariate and multivariate statistics, such as measures of dispersion, principal components, and cumulative sums},
  timestamp = {2015-06-03T08:05:38Z},
  number = {2},
  urldate = {2015-06-03},
  journal = {Technometrics},
  author = {Fuchs, Camil and Benjamini, Yoav},
  month = may,
  year = {1994},
  pages = {182--195},
  file = {Fuchs_Benjamini_1994_Multivariate Profile Charts for Statistical Process Control.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/DJ7R8XGJ/Fuchs_Benjamini_1994_Multivariate Profile Charts for Statistical Process Control.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/Q5K5SQRG/00401706.1994.html:text/html}
}

@book{_modern_2001,
  address = {New York},
  edition = {2 edition},
  title = {Modern {{Methods For Quality Control}} and {{Improvement}}},
  isbn = {978-0-471-29973-8},
  language = {English},
  timestamp = {2015-07-22T18:12:38Z},
  publisher = {{Wiley}},
  month = nov,
  year = {2001}
}

@book{wheeler_understanding_2010,
  address = {Knoxville, Tenn},
  title = {Understanding {{Statistical Process Control}}},
  isbn = {978-0-945320-69-2},
  language = {English},
  timestamp = {2015-07-22T18:21:42Z},
  publisher = {{SPC PRESS}},
  author = {Wheeler, Donald J.},
  month = jun,
  year = {2010}
}

@misc{_yhat_????,
  title = {{\^Y}hat | {{Statistical Quality Control}} in {{R}}},
  abstract = {Quality Control and quality assurance are important functions in most businesses from manufacturing to software development. For most, this means that one or more people are meticulously inspecting what's coming out of the factory, looking for imperfections and validating that requirements for products and services produced are satisfied. Often times QC and QA are performed manually by a select few specialists, and determining suitable quality can be extremely complex and error-prone.

This is a post about quality assurance automation ...},
  timestamp = {2015-07-22T18:40:58Z},
  urldate = {2015-07-22},
  howpublished = {\url{http://blog.yhathq.com/posts/quality-control-in-r.html}},
  journal = {{\^y}hat | Blog},
  file = {Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/BBENXMQI/quality-control-in-r.html:text/html}
}

@book{qiu_introduction_2013,
  address = {Boca Raton},
  title = {Introduction to {{Statistical Process Control}}},
  isbn = {978-1-4398-4799-2},
  abstract = {A major tool for quality control and management, statistical process control (SPC) monitors sequential processes, such as production lines and Internet traffic, to ensure that they work stably and satisfactorily. Along with covering traditional methods, Introduction to Statistical Process Control describes many recent SPC methods that improve upon the more established techniques. The author\textemdash{}a leading researcher on SPC\textemdash{}shows how these methods can handle new applications.  After exploring the role of SPC and other statistical methods in quality control and management, the book covers basic statistical concepts and methods useful in SPC. It then systematically describes traditional SPC charts, including the Shewhart, CUSUM, and EWMA charts, as well as recent control charts based on change-point detection and fundamental multivariate SPC charts under the normality assumption. The text also introduces novel univariate and multivariate control charts for cases when the normality assumption is invalid and discusses control charts for profile monitoring. All computations in the examples are solved using R, with R functions and datasets available for download on the author's website.   Offering a systematic description of both traditional and newer SPC methods, this book is ideal as a primary textbook for a one-semester course in disciplines concerned with process quality control, such as statistics, industrial and systems engineering, and management sciences. It can also be used as a supplemental textbook for courses on quality improvement and system management. In addition, the book provides researchers with many useful, recent research results on SPC and gives quality control practitioners helpful guidelines on implementing up-to-date SPC techniques.},
  language = {English},
  timestamp = {2015-08-26T20:55:58Z},
  publisher = {{Chapman and Hall/CRC}},
  author = {Qiu, Peihua},
  month = oct,
  year = {2013}
}

@book{_encyclopedia_2006,
  address = {Singapore ; Hackensack, NJ},
  title = {Encyclopedia {{And Handbook}} of {{Process Capability Indices}}: {{A Comprehensive Exposition}} of {{Quality Control Measures}}},
  isbn = {978-981-256-759-8},
  shorttitle = {Encyclopedia {{And Handbook}} of {{Process Capability Indices}}},
  language = {English},
  timestamp = {2015-10-28T10:55:07Z},
  publisher = {{World Scientific Pub Co Inc}},
  month = may,
  year = {2006}
}

@article{masuda_multivariate_2014,
  title = {Multivariate {{Statistical Process Control Method Including Soft Sensors}} for {{Both Early}} and {{Accurate Fault Detection}}},
  volume = {53},
  issn = {0888-5885},
  doi = {10.1021/ie501024w},
  abstract = {The development of process monitoring and control methods is important to maintaining product quality in chemical plants safely and effectively. Therefore, multivariate statistical process control (MSPC) methods have been developed, but traditional MSPC methods cannot detect faults relating to process variables that are difficult to measure online. In this work, a new MSPC method including soft sensor prediction is proposed to solve this problem. Soft sensors predict values of difficult-to-measure variables that are used as input variables of fault detection models. The proposed method enables the real-time control of processes using difficult-to-measure variables. The fault detection performance of the proposed method is demonstrated and compared with that of traditional MSPC methods using the Tennessee Eastman process and real industrial process data sets. The results show that the proposed method can achieve more accurate and earlier fault detection than traditional MSPC methods.},
  timestamp = {2015-10-28T10:56:08Z},
  number = {20},
  urldate = {2015-10-28},
  journal = {Industrial \& Engineering Chemistry Research},
  author = {Masuda, Yasuyuki and Kaneko, Hiromasa and Funatsu, Kimito},
  month = may,
  year = {2014},
  pages = {8553--8564},
  file = {ACS Full Text Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/D8PSVH6V/ie501024w.html:text/html}
}

@book{montgomery_introduction_2007,
  title = {Introduction to Statistical Quality Control},
  timestamp = {2015-10-28T17:38:32Z},
  publisher = {{John Wiley \& Sons}},
  author = {Montgomery, Douglas C},
  year = {2007}
}

@book{wikipedia_quality_2015,
  title = {Quality (Business) \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-10-28T17:53:06Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 28-October-2015]}
}

@book{wikipedia_eight_2015,
  title = {Eight Dimensions of Quality \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-10-28T18:45:11Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 28-October-2015]}
}

@book{wikipedia_zero_2015,
  title = {Zero {{Defects}} \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-10-29T09:19:14Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 29-October-2015]}
}

@book{wikipedia_value_2015,
  title = {Value Engineering \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-10-29T09:21:59Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 29-October-2015]}
}

@book{wikipedia_lean_2015,
  title = {Lean Manufacturing \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-10-29T11:11:42Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 29-October-2015]}
}

@book{wikipedia_design_2015,
  title = {Design for {{Six Sigma}} \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-10-29T11:11:54Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 29-October-2015]}
}

@article{rodgers_thirteen_1988,
  title = {Thirteen {{Ways}} to {{Look}} at the {{Correlation Coefficient}}},
  volume = {42},
  issn = {0003-1305},
  doi = {10.1080/00031305.1988.10475524},
  abstract = {In 1885, Sir Francis Galton first defined the term ``regression'' and completed the theory of bivariate correlation. A decade later, Karl Pearson developed the index that we still use to measure correlation, Pearson's r. Our article is written in recognition of the 100th anniversary of Galton's first discussion of regression and correlation. We begin with a brief history. Then we present 13 different formulas, each of which represents a different computational and conceptual definition of r. Each formula suggests a different way of thinking about this index, from algebraic, geometric, and trigonometric settings. We show that Pearson's r (or simple functions of r) may variously be thought of as a special type of mean, a special type of variance, the ratio of two means, the ratio of two variances, the slope of a line, the cosine of an angle, and the tangent to an ellipse, and may be looked at from several other interesting perspectives.},
  timestamp = {2015-10-29T21:49:44Z},
  number = {1},
  urldate = {2015-10-29},
  journal = {The American Statistician},
  author = {Rodgers, Joseph Lee and Nicewander, W. Alan},
  month = feb,
  year = {1988},
  pages = {59--66},
  file = {Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/NDQAD5TU/00031305.1988.html:text/html}
}

@article{woodall_controversies_2000,
  title = {Controversies and Contradictions in Statistical Process Control},
  volume = {32},
  timestamp = {2015-11-01T11:10:14Z},
  number = {4},
  urldate = {2015-11-01},
  journal = {Journal of Quality Technology},
  author = {Woodall, William H.},
  year = {2000},
  pages = {341--350},
  file = {Woodall_2000_Controversies and contradictions in statistical process control.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/PI5ZQPCJ/Woodall_2000_Controversies and contradictions in statistical process control.pdf:application/pdf}
}

@book{basseville_detection_1993,
  title = {Detection of Abrupt Changes: Theory and Application},
  volume = {104},
  shorttitle = {Detection of Abrupt Changes},
  timestamp = {2015-11-04T13:15:09Z},
  urldate = {2015-11-04},
  publisher = {{Prentice Hall Englewood Cliffs}},
  author = {Basseville, Mich{\`e}le and Nikiforov, Igor V. and {others}},
  year = {1993}
}

@article{ritov_decision_1990,
  title = {Decision {{Theoretic Optimality}} of the {{Cusum Procedure}}},
  volume = {18},
  copyright = {Copyright \textcopyright{} 1990 Institute of Mathematical Statistics},
  issn = {0090-5364},
  abstract = {Suppose X1, X2, ... are independent random variables such that for some unknown $\nu$, each of X1, ..., X$\nu$ - 1 is distributed according to F0, while X$\nu$, X$\nu$ + 1, ... are all distributed according to F1. We prove a result of Moustakides that claims that the CUSUM procedures are optimal in the sense of Lorden. We do that by proving that the procedures are Bayes for some stochastic mechanism of generating $\nu$.},
  timestamp = {2015-11-04T15:59:04Z},
  number = {3},
  urldate = {2015-11-04},
  journal = {The Annals of Statistics},
  author = {Ritov, Y.},
  month = sep,
  year = {1990},
  pages = {1464--1469},
  file = {Ritov_1990_Decision Theoretic Optimality of the Cusum Procedure.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TGN729EP/Ritov_1990_Decision Theoretic Optimality of the Cusum Procedure.pdf:application/pdf}
}

@article{page_continuous_1954,
  title = {Continuous {{Inspection Schemes}}},
  volume = {41},
  issn = {0006-3444, 1464-3510},
  doi = {10.1093/biomet/41.1-2.100},
  language = {en},
  timestamp = {2015-11-04T19:15:59Z},
  number = {1-2},
  urldate = {2015-11-04},
  journal = {Biometrika},
  author = {Page, E. S.},
  month = jan,
  year = {1954},
  pages = {100--115},
  file = {Page_1954_Continuous Inspection Schemes.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/2CTNDXHR/Page_1954_Continuous Inspection Schemes.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZV3BPNE7/100.html:text/html}
}

@book{wikipedia_receiver_2015,
  title = {Receiver Operating Characteristic \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-11-06T07:38:21Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 6-November-2015]}
}

@article{woodall_statistical_1993,
  title = {The {{Statistical Design}} of {{Cusum Charts}}},
  volume = {5},
  issn = {0898-2112},
  doi = {10.1080/08982119308918998},
  timestamp = {2015-11-06T12:19:03Z},
  number = {4},
  urldate = {2015-11-06},
  journal = {Quality Engineering},
  author = {WOODALL, WILLIAM H. and ADAMS, BENJAMIN M.},
  month = jan,
  year = {1993},
  pages = {559--570},
  file = {Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/EMJN6935/08982119308918998.html:text/html}
}

@article{moustakides_optimal_1986,
  title = {Optimal {{Stopping Times}} for {{Detecting Changes}} in {{Distributions}}},
  volume = {14},
  copyright = {Copyright \textcopyright{} 1986 Institute of Mathematical Statistics},
  issn = {0090-5364},
  abstract = {It is shown that Page's stopping time is optimal for the detection of changes in distributions, in a well defined sense. This work is a generalization of an existing result where it was shown that Page's stopping time is optimal asymptotically.},
  timestamp = {2015-11-06T12:30:44Z},
  number = {4},
  urldate = {2015-11-06},
  journal = {The Annals of Statistics},
  author = {Moustakides, George V.},
  month = dec,
  year = {1986},
  pages = {1379--1387},
  file = {Moustakides_1986_Optimal Stopping Times for Detecting Changes in Distributions.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZENHCXPR/Moustakides_1986_Optimal Stopping Times for Detecting Changes in Distributions.pdf:application/pdf}
}

@article{moustakides_optimality_2004,
  title = {Optimality of the {{CUSUM Procedure}} in {{Continuous Time}}},
  volume = {32},
  copyright = {Copyright \textcopyright{} 2004 Institute of Mathematical Statistics},
  issn = {0090-5364},
  abstract = {The optimality of CUSUM under a Lorden-type criterion setting is considered. We demonstrate the optimality of the CUSUM test for It{\^o} processes, in a sense similar to Lorden's, but with a criterion that replaces expected delays by the corresponding Kullback-Leibler divergence.},
  timestamp = {2015-11-06T12:31:13Z},
  number = {1},
  urldate = {2015-11-06},
  journal = {The Annals of Statistics},
  author = {Moustakides, George V.},
  month = feb,
  year = {2004},
  pages = {302--315},
  file = {Moustakides_2004_Optimality of the CUSUM Procedure in Continuous Time.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/2T3DQP5X/Moustakides_2004_Optimality of the CUSUM Procedure in Continuous Time.pdf:application/pdf}
}

@incollection{umit_multivariate_2001,
  title = {Multivariate {{Quality Control}}: {{A Historical Perspective}}.},
  shorttitle = {Multivariate {{Quality Control}}},
  timestamp = {2015-11-06T15:06:54Z},
  publisher = {{Yilditz Technical University}},
  author = {Umit, F and Cigdem, A},
  year = {2001},
  keywords = {statistical_techniques,Statistics},
  pages = {54--65},
  file = {Umit_Cigdem_2001_Multivariate Quality Control.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/HVFE82AS/Umit_Cigdem_2001_Multivariate Quality Control.pdf:application/pdf}
}

@article{berman_limit_1964,
  title = {Limit {{Theorems}} for the {{Maximum Term}} in {{Stationary Sequences}}},
  volume = {35},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177703551},
  abstract = {Let \{Xn,n=0,$\pm$1,$\cdots$\}$\backslash$\{X\_n, n = 0, $\backslash$pm 1, $\backslash$cdots$\backslash$\} be a real valued discrete parameter stationary stochastic process on a probability space ($\Omega$,$\mathscr{F}$,P);($\backslash$Omega, $\backslash$mathscr\{F\}, P); for each n=1,2,$\cdots$n = 1, 2, $\backslash$cdots, let Zn=max(X1,$\cdots$,Xn)Z\_n = $\backslash$max (X\_1, $\backslash$cdots, X\_n). We shall find general conditions under which the random variable ZnZ\_n has a limiting distribution function (d.f.) as n$\rightarrow\infty$n $\backslash$rightarrow $\backslash$infty; that is, there exist sequences \{an\}$\backslash$\{a\_n$\backslash$\} and \{bn\},an$>$0$\backslash$\{b\_n$\backslash$\}, a\_n $>$ 0, and a proper nondegenerate d.f. $\Phi$(x)$\backslash$Phi(x) such that limn$\rightarrow\infty$P\{Zn$\leqq$anx+bn\}=$\Phi$(x)(1.1)$\backslash$begin\{equation*\}$\backslash$tag\{1.1\}$\backslash$lim\_\{n $\backslash$rightarrow $\backslash$infty\} P$\backslash$\{Z\_n $\backslash$leqq a\_nx + b\_n$\backslash$\} = $\backslash$Phi(x)$\backslash$end\{equation*\} for each xx in the continuity set of $\Phi$(x)$\backslash$Phi(x). The simplest type of stationary sequence \{Xn\}$\backslash$\{X\_n$\backslash$\} is one in which the random variables are mutually independent with some common d.f. F(x)F(x). In this case, ZnZ\_n has the d.f. Fn(x)F\^n(x) and (1.1) becomes limn$\rightarrow\infty$Fn(anx+bn)=$\Phi$(x).(1.2)$\backslash$begin\{equation*\}$\backslash$tag\{1.2\}$\backslash$lim\_\{n $\backslash$rightarrow $\backslash$infty\} F\^n(a\_nx + b\_n) = $\backslash$Phi(x).$\backslash$end\{equation*\} It is well known that in (1.2) $\Phi$(x)$\backslash$Phi(x) is of one of exactly three types; necessary and sufficient conditions on FF for the validity of (1.2) are also known [9]. The three types are usually called extreme value d.f.'s [10]. Theorem 2.1 gives the limiting d.f. of ZnZ\_n in a stationary sequence satisfying a certain condition on the upper tail of the conditional d.f. of X1X\_1, given the "past" of sequence: the limiting d.f. is a simple mixture of extreme value d.f.'s of a single type. These are the same kind of d.f.'s found by us [3] to be the limiting d.f.'s of maxima in sequences of exchangeable random variables. The conditions of Theorem 2.1 are specialized to exchangeable and Markov sequences, and Theorem 2.2 extends the methods of Theorem 2.1 to general (not necessarily stationary) Markov sequences. It is shown that stationary Gaussian sequences, except for the trivial case of independent, identically distributed Gaussian random variables, do not obey the requirements of the hypothesis of Theorem 2.1: hence, Sections 3, 4, and 5 are devoted to a detailed study of the maximum in a stationary Gaussian sequence. Theorem 3.1 provides conditions on the rate of convergence of the covariance sequence to 0 which are sufficient for ZnZ\_n to have the same extreme value limiting d.f. as in the case of independence, namely, exp(-e-x)$\backslash$exp (-e\^\{-x\}). The relation of these conditions to the spectral d.f. of the process is also discussed. A weaker condition on the covariance sequence ensures the "relative stability in probability" of ZnZ\_n (Theorem 4.1). Theorem 5.1 describes the behavior of ZnZ\_n when the spectrum has a discrete component with "not too many large jumps" and a "smooth" continuous component: when properly normalized, ZnZ\_n converges in probability to a random variable representing the maximum of the process corresponding to the discrete spectral component. A special case was given by us in [2]. We now summarize some known results used in the sequel. The extreme value d.f.'s are continuous, so that (1.2) holds for all xx; furthermore, this holds if and only if it holds for all xx satisfying 0$<$$\Phi$(x)$<$1.0 $<$ $\backslash$Phi(x) $<$ 1. (1.2) implies that for all such xx 0$<$Fn(anx+bn)$<$1,for all largen,0 $<$ F\^n (a\_nx + b\_n) $<$ 1,$\backslash$quad$\backslash$text\{for all large\} n, and limn$\rightarrow\infty$F(anx+bn)=1.(1.3)$\backslash$begin\{equation*\}$\backslash$tag\{1.3\}$\backslash$lim\_\{n $\backslash$rightarrow $\backslash$infty\} F(a\_nx + b\_n) = 1.$\backslash$end\{equation*\} Let x$\infty$x\_$\backslash$infty be the supremum of all real numbers x${'}$x' for which F(x${'}$)$<$1F(x') $<$ 1; then, for all xx satisfying 0$<$$\Phi$(x)$<$10 $<$ $\backslash$Phi(x) $<$ 1, we have limn$\rightarrow\infty$anx+bn=x$\infty$.(1.4)$\backslash$begin\{equation*\}$\backslash$tag\{1.4\}$\backslash$lim\_\{n $\backslash$rightarrow $\backslash$infty\} a\_nx + b\_n = x\_$\backslash$infty.$\backslash$end\{equation*\} From (1.3), and the asymptotic relation -logF$\sim$(1-F),F$\rightarrow$1-$\backslash$log F $\backslash$sim (1 - F), F $\backslash$rightarrow 1, we see that (1.2) holds if and only if limn$\rightarrow\infty$n[1-F(anx+bn)]=-log$\Phi$(x).(1.5)$\backslash$begin\{equation*\}$\backslash$tag\{1.5\}$\backslash$lim\_\{n $\backslash$rightarrow $\backslash$infty\} n$\backslash$lbrack 1 - F (a\_nx + b\_n)$\backslash$rbrack = -$\backslash$log $\backslash$Phi(x).$\backslash$end\{equation*\}},
  language = {EN},
  timestamp = {2015-11-06T16:14:39Z},
  number = {2},
  urldate = {2015-11-06},
  journal = {The Annals of Mathematical Statistics},
  author = {Berman, Simeon M.},
  month = jun,
  year = {1964},
  pages = {502--516},
  file = {Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/XT6TM2Q6/DPubS.html:text/html},
  mrnumber = {MR161365},
  zmnumber = {0122.13503}
}

@article{girshick_bayes_1952,
  title = {A {{Bayes Approach}} to a {{Quality Control Model}}},
  volume = {23},
  copyright = {Copyright \textcopyright{} 1952 Institute of Mathematical Statistics},
  issn = {0003-4851},
  abstract = {This paper deals with a class of statistical quality control procedures and continuous inspection procedures which are optimum for a specified income function and a production model which can only be in one of four states, two of which are states of repair, with known transition probabilities. The Markov process, generated by the model and the class of decision procedures, approaches a limiting distribution and the integral equations from which the optimum procedures can be derived are given.},
  timestamp = {2015-11-06T21:20:11Z},
  number = {1},
  urldate = {2015-11-06},
  journal = {The Annals of Mathematical Statistics},
  author = {Girshick, M. A. and Rubin, Herman},
  month = mar,
  year = {1952},
  pages = {114--125},
  file = {Girshick_Rubin_1952_A Bayes Approach to a Quality Control Model.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/34MV9IIH/Girshick_Rubin_1952_A Bayes Approach to a Quality Control Model.pdf:application/pdf}
}

@article{duncan_economic_1956,
  title = {The {{Economic Design}} of {{X Charts Used}} to {{Maintain Current Control}} of a {{Process}}},
  volume = {51},
  issn = {0162-1459},
  doi = {10.1080/01621459.1956.10501322},
  abstract = {This paper establishes a criterion that measures approximately the average net income of a process under surveillance of an X chart when the process is subject to random shifts in the process mean. The quality control rule assumed is that an assignable cause is looked for whenever a point falls outside the control limits. The criterion is for the case in which it is assumed that the process is not shut down while the search for the assignable cause is in progress, nor is the cost of adjustment or repair and the cost of bringing the process back into a state of control after the assignable cause is discovered charged to the control chart program. The paper shows how to determine the sample size, the interval between samples, and the control limits that will yield approximately maximum average net income. Numerical examples of optimum design are studied to see how variation in the various risk and cost factors affects the optimum. * The writer is greatly indebted to I. R. Savage and G. Greggory of Stanford University for their criticism and suggestions in preparation of this paper. The paper was completed while the writer was working at Stanford University under the auspices of the Office of Naval Research.},
  timestamp = {2015-11-06T21:46:08Z},
  number = {274},
  urldate = {2015-11-06},
  journal = {Journal of the American Statistical Association},
  author = {Duncan, Acheson J.},
  month = jun,
  year = {1956},
  pages = {228--242},
  file = {Duncan_1956_The Economic Design of X Charts Used to Maintain Current Control of a Process.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/EMWMWXAN/Duncan_1956_The Economic Design of X Charts Used to Maintain Current Control of a Process.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/2FMCSHZ6/01621459.1956.html:text/html}
}

@book{natrella_nist/sematech_2010,
  title = {{{NIST}}/{{SEMATECH}} E-{{Handbook}} of {{Statistical Methods}}},
  abstract = {The NIST/SEMATECH e-Handbook of Statistical Methods1, is a Web-based book whose goal is to help scientists and engineers incorporate statistical methods into their work as  efficiently as possible. Ideally it will serve as a reference that will help scientists and engineers design their own experiments and carry out the appropriate analyses when a statistician is not available to help. It is also hoped that it will serve as a useful educational tool that will help users of statistical methods and consumers of statistical information better understand statistical procedures and their underlying assumptions and more clearly interpret scientific and engineering results stated in statistical terms.},
  timestamp = {2015-11-08T06:39:24Z},
  urldate = {2015-11-08},
  publisher = {{NIST/SEMATECH}},
  author = {Natrella, Mary},
  editor = {Croarkin, Carroll and Tobias, Paul and Filliben, James and Hembree, Barry and Guthrie, William and Trutna, Ledi and Prins, Jack},
  month = jul,
  year = {2010},
  keywords = {e-handbook,nist,sematech,statistical_methods}
}

@book{hocking_analysis_1985,
  title = {The Analysis of Linear Models},
  timestamp = {2015-11-10T14:57:11Z},
  publisher = {{Brooks/Cole Pub Co}},
  author = {Hocking, Ronald R},
  year = {1985}
}

@book{greene_econometric_2003,
  title = {Econometric Analysis},
  timestamp = {2015-11-10T14:58:53Z},
  publisher = {{Pearson Education India}},
  author = {Greene, William H},
  year = {2003}
}

@book{fisher_design_1960,
  title = {The Design of Experiments},
  volume = {12},
  timestamp = {2015-11-10T15:09:52Z},
  number = {6},
  publisher = {{Oliver and Boyd Edinburgh}},
  author = {Fisher, Sir Ronald Aylmer},
  year = {1960}
}

@book{mason_statistical_2003,
  title = {Statistical Design and Analysis of Experiments: With Applications to Engineering and Science},
  volume = {474},
  timestamp = {2015-11-10T15:17:54Z},
  publisher = {{John Wiley \& Sons}},
  author = {Mason, Robert L and Gunst, Richard F and Hess, James L},
  year = {2003}
}

@book{rosenbaum_observational_2002,
  title = {Observational Studies},
  timestamp = {2015-11-10T15:45:51Z},
  publisher = {{Springer}},
  author = {Rosenbaum, Paul R},
  year = {2002}
}

@book{cox_theory_2000,
  title = {The {{Theory}} of the {{Design}} of {{Experiments}}},
  isbn = {978-1-4200-3583-4},
  abstract = {Why study the theory of experiment design? Although it can be useful to know about special designs for specific purposes, experience suggests that a particular design can rarely be used directly. It needs adaptation to accommodate the circumstances of the experiment. Successful designs depend upon adapting general theoretical principles to the special constraints of individual applications. Written for a general audience of researchers across the range of experimental disciplines, The Theory of the Design of Experiments presents the major topics associated with experiment design, focusing on the key concepts and the statistical structure of those concepts. The authors keep the level of mathematics elementary, for the most part, and downplay methods of data analysis. Their emphasis is firmly on design, but appendices offer self-contained reviews of algebra and some standard methods of analysis.From their development in association with agricultural field trials, through their adaptation to the physical sciences, industry, and medicine, the statistical aspects of the design of experiments have become well refined. In statistics courses of study, however, the design of experiments very often receives much less emphasis than methods of analysis. The Theory of the Design of Experiments fills this potential gap in the education of practicing statisticians, statistics students, and researchers in all fields.},
  language = {en},
  timestamp = {2015-11-11T12:47:02Z},
  publisher = {{CRC Press}},
  author = {Cox, D. R. and Reid, Nancy},
  month = jun,
  year = {2000},
  keywords = {Mathematics / General,Mathematics / Probability \& Statistics / General,Science / Life Sciences / Biology}
}

@book{ge_multivariate_2012,
  title = {Multivariate {{Statistical Process Control}}: {{Process Monitoring Methods}} and {{Applications}}},
  isbn = {978-1-4471-4513-4},
  shorttitle = {Multivariate {{Statistical Process Control}}},
  abstract = {Given their key position in the process control industry, process monitoring techniques have been extensively investigated by industrial practitioners and academic control researchers. Multivariate statistical process control (MSPC) is one of the most popular data-based methods for process monitoring and is widely used in various industrial areas. Effective routines for process monitoring can help operators run industrial processes efficiently at the same time as maintaining high product quality. Multivariate Statistical Process Control reviews the developments and improvements that have been made to MSPC over the last decade, and goes on to propose a series of new MSPC-based approaches for complex process monitoring. These new methods are demonstrated in several case studies from the chemical, biological, and semiconductor industrial areas.  Control and process engineers, and academic researchers in the process monitoring, process control and fault detection and isolation (FDI) disciplines will be interested in this book. It can also be used to provide supplementary material and industrial insight for graduate and advanced undergraduate students, and graduate engineers. Advances in Industrial Control aims to report and encourage the transfer of technology in control engineering. The rapid development of control technology has an impact on all areas of the control discipline. The series offers an opportunity for researchers to present an extended exposition of new work in all aspects of industrial control.},
  language = {en},
  timestamp = {2015-11-11T12:50:14Z},
  publisher = {{Springer Science \& Business Media}},
  author = {Ge, Zhiqiang and Song, Zhihuan},
  month = nov,
  year = {2012},
  keywords = {Business \& Economics / Production \& Operations Management,Technology \& Engineering / Automation,Technology \& Engineering / Electrical,Technology \& Engineering / Industrial Technology}
}

@book{kotz_process_1993,
  title = {Process {{Capability Indices}}},
  isbn = {978-0-412-54380-7},
  abstract = {A solid, rigorous, yet comprehensible analysis of process capability indices, this work bridges the gap between theoretical statisticians and quality control practitioners, showing how an understanding of these indices can lead to process improvement.},
  language = {en},
  timestamp = {2015-11-11T12:58:39Z},
  publisher = {{CRC Press}},
  author = {Kotz, Samuel and Johnson, Norman L.},
  month = jun,
  year = {1993},
  keywords = {Business \& Economics / Quality Control,Mathematics / Probability \& Statistics / General}
}

@book{wadsworth_modern_1986,
  title = {Modern {{Methods}} for {{Quality Control}} and {{Improvement}}},
  isbn = {978-0-471-84326-9},
  abstract = {This is a detailed presentation of modern quality control methods and systems, written by three researchers in the field. It strikes a balance between theoretical and practical aspects of quality control, and treats the traditional principles and techniques of statistical quality control and quality assurance using the most modern approaches. The book is designed for advanced undergraduate or graduate students in industrial engineering and management.},
  language = {en},
  timestamp = {2015-11-11T12:58:58Z},
  publisher = {{Wiley}},
  author = {Wadsworth, Harrison M. and Stephens, Kenneth S. and Godfrey, A. Blanton},
  year = {1986}
}

@book{geoffrey_m._clarke_introduction_2010,
  address = {New York, N.Y.},
  edition = {1 edition},
  title = {Introduction to the {{Design}} and {{Analysis}} of {{Experiments}}},
  isbn = {978-0-470-71107-1},
  language = {English},
  timestamp = {2015-11-11T17:45:42Z},
  publisher = {{Wiley}},
  author = {{Geoffrey M. Clarke} and {Robert E. Kempson}},
  month = may,
  year = {2010}
}

@book{angela_m._dean_design_2000,
  address = {New York},
  edition = {Corrected edition},
  title = {Design and {{Analysis}} of {{Experiments}}},
  isbn = {978-0-387-98561-9},
  language = {English},
  timestamp = {2015-11-11T17:45:59Z},
  publisher = {{Springer}},
  author = {{Angela M. Dean} and {Daniel Voss}},
  month = dec,
  year = {2000}
}

@book{everitt_cambridge_2010,
  address = {Cambridge, UK ; New York},
  edition = {4 edition},
  title = {The {{Cambridge Dictionary}} of {{Statistics}}},
  isbn = {978-0-521-76699-9},
  language = {English},
  timestamp = {2015-11-11T21:40:06Z},
  publisher = {{Cambridge University Press}},
  author = {Everitt, B. S. and Skrondal, Anders},
  month = oct,
  year = {2010}
}

@book{hill_first_1986,
  title = {A {{First Course}} in {{Coding Theory}}},
  isbn = {978-0-19-853803-5},
  abstract = {Algebraic coding theory is a new and rapidly developing subject, popular for its many practical applications and for its fascinatingly rich mathematical structure. This book provides an elementary yet rigorous introduction to the theory of error-correcting codes. Based on courses given by the author over several years to advanced undergraduates and first-year graduated students, this guide includes a large number of exercises, all with solutions, making the book highly suitable for individual study.},
  language = {en},
  timestamp = {2015-11-11T22:28:00Z},
  publisher = {{Clarendon Press}},
  author = {Hill, Raymond},
  year = {1986},
  keywords = {Technology \& Engineering / Agriculture / General}
}

@book{montgomery_design_2012,
  address = {Hoboken, NJ},
  edition = {8 edition},
  title = {Design and {{Analysis}} of {{Experiments}}},
  isbn = {978-1-118-14692-7},
  language = {English},
  timestamp = {2015-11-12T06:40:19Z},
  publisher = {{Wiley}},
  author = {Montgomery, Douglas},
  month = apr,
  year = {2012}
}

@book{hedayat_orthogonal_1999,
  title = {Orthogonal {{Arrays}}: {{Theory}} and {{Applications}}},
  isbn = {978-0-387-98766-8},
  shorttitle = {Orthogonal {{Arrays}}},
  abstract = {This is the first book on the subject since its introduction more than fifty years ago, and it can be used as a graduate text or as a reference work. It features all of the key results, many very useful tables, and a large number of research problems. The book will be of interest to those interested in one of the most fascinating areas of discrete mathematics, connected to statistics and coding theory, with applications to computer science and cryptography. It will be useful for anyone who is running experiments, whether in a chemistry lab or a manufacturing plant (trying to make those alloys stronger), or in agricultural or medical research. Sam Hedayat is Professor of Statistics and Senior Scholar in the Department of Mathematics, Statistics, and Computer Science, University of Illinois, Chicago. Neil J.A. Sloane is with AT\&T Bell Labs (now AT\&T Labs). John Stufken is Professor Statistics at Iowa State University.},
  language = {en},
  timestamp = {2015-11-12T08:20:47Z},
  publisher = {{Springer Science \& Business Media}},
  author = {Hedayat, A. S. and Sloane, N. J. A. and Stufken, John},
  month = jun,
  year = {1999},
  keywords = {Mathematics / Group Theory,Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{wikipedia_optimal_2015,
  title = {Optimal Design \textemdash{} {{Wikipedia}}, {{The Free Encyclopedia}}},
  timestamp = {2015-11-13T12:52:25Z},
  author = {{Wikipedia}},
  year = {2015},
  note = {[Online; accessed 13-November-2015]}
}

@article{wald_sequential_1945,
  title = {Sequential Tests of Statistical Hypotheses},
  volume = {16},
  timestamp = {2015-11-13T13:17:26Z},
  number = {2},
  urldate = {2015-11-13},
  journal = {The Annals of Mathematical Statistics},
  author = {Wald, Abraham},
  year = {1945},
  pages = {117--186}
}

@article{sacks_design_1989,
  title = {Design and Analysis of Computer Experiments},
  timestamp = {2015-11-13T14:59:17Z},
  urldate = {2015-11-13},
  journal = {Statistical science},
  author = {Sacks, Jerome and Welch, William J. and Mitchell, Toby J. and Wynn, Henry P.},
  year = {1989},
  pages = {409--423}
}

@book{santner_design_2013,
  title = {The {{Design}} and {{Analysis}} of {{Computer Experiments}}},
  isbn = {978-1-4757-3799-8},
  abstract = {In the past 15 to 20 years, the computer has become a popular tool for exploring the relationship between a measured response and factors thought to affect the response. In many cases, scientific theories exist that implicitly relate the response to the factors by means of systems of mathematical equations. There also exist numerical methods for accurately solving such equations and appropriate computer hardware and software to implement these methods. In many engineering applications, for example, the relationship is described by a dynamical system and the numerical method is a finite element code. In such situations, these numerical methods allow one to produce computer code that can generate the response corresponding to any given set of values of the factors. This allows one to conduct an "experiment" (called a "computer experiment") to explore the relationship between the response and the factors using the code. Indeed, in some cases computer experimentation is feasible when a properly designed physical experiment (the gold standard for establishing cause and effect) is impossible. For example, the number of input variables may be too large to consider performing a physical experiment or it may simply be economically prohibitive to run an experiment on the scale required to gather sufficient information to answer a particular research question. This book describes methods for designing and analyzing experiments conducted using computer code in lieu of a physical experiment. It discusses how to select the values of the factors at which to run the code (the design of the computer experiment) in light of the research objectives of the experimenter. It also provides techniques for analyzing the resulting data so as to achieve these research goals. It illustrates these methods with code that is available to the reader at},
  language = {en},
  timestamp = {2015-11-13T14:59:34Z},
  publisher = {{Springer Science \& Business Media}},
  author = {Santner, Thomas J. and Williams, Brian J. and Notz, William I.},
  month = mar,
  year = {2013},
  keywords = {Computers / Computer Simulation,Computers / Desktop Applications / Design \& Graphics,Mathematics / Applied,Mathematics / Counting \& Numeration,Mathematics / Numerical Analysis,Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{aven_stochastic_1999,
  title = {Stochastic Models in Reliability},
  timestamp = {2015-11-15T11:15:53Z},
  urldate = {2015-11-15},
  publisher = {{Springer}},
  author = {Aven, Terje and Jensen, Uwe},
  year = {1999},
  file = {Aven_Jensen_1999_Stochastic models in reliability.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/WQ86ZUZJ/Aven_Jensen_1999_Stochastic models in reliability.pdf:application/pdf}
}

@article{nadarajah_bathtub-shaped_2008,
  title = {Bathtub-Shaped Failure Rate Functions},
  volume = {43},
  issn = {0033-5177, 1573-7845},
  doi = {10.1007/s11135-007-9152-9},
  abstract = {The failure rate function is an important quantity characterizing life phenomena. Ideally, one would expect this function to exhibit a bathtub shape. In this paper, a comprehensive review of the known distributions that exhibit this shape is provided. Over 17 such distributions are identified. This review is especially important because almost all of the commonly known distributions in statistics do not exhibit the bathtub shape. Furthermore, it could serve as an important reference and encourage developments of further distributions that exhibit a bathtub shape.},
  language = {en},
  timestamp = {2015-11-15T13:04:09Z},
  number = {5},
  urldate = {2015-11-15},
  journal = {Quality \& Quantity},
  author = {Nadarajah, Saralees},
  month = jan,
  year = {2008},
  keywords = {Bathtub shape,Failure rate function,Methodology of the Social Sciences,Social Sciences; general,Weibull distribution},
  pages = {855--863},
  file = {Nadarajah_2008_Bathtub-shaped failure rate functions.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/6SSS96GZ/Nadarajah_2008_Bathtub-shaped failure rate functions.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TWM29DJK/s11135-007-9152-9.html:text/html}
}

@book{nahmias_production_2015,
  title = {Production and {{Operations Analysis}}: {{Seventh Edition}}},
  isbn = {978-1-4786-2824-8},
  shorttitle = {Production and {{Operations Analysis}}},
  abstract = {The Seventh Edition of Production and Operations Analysis builds a  solid foundation for beginning students of production and operations  management. Continuing a long tradition of excellence, Nahmias and Olsen  bring decades of combined experience to craft the most clear and  up-to-date resource available. The authors' thorough updates include  incorporation of current technology that improves the effectiveness of  production processes, additional qualitative sections, and new material  on service operations management and servicization. Bolstered by copious  examples and problems, each chapter stands alone, allowing instructors  to tailor the material to their specific needs. The text is essential  reading for learning how to better analyze and improve on all facets of  operations.},
  language = {en},
  timestamp = {2015-11-15T15:25:37Z},
  publisher = {{Waveland Press}},
  author = {Nahmias, Steven and Olsen, Tava Lennon},
  month = jan,
  year = {2015},
  keywords = {Business \& Economics / Production \& Operations Management,Technology \& Engineering / Industrial Engineering,Technology \& Engineering / Operations Research}
}

@article{bagnoli_log-concave_2005,
  title = {Log-{{Concave Probability}} and {{Its Applications}}},
  volume = {26},
  issn = {0938-2259},
  abstract = {In many applications, assumptions about the log-concavity of a probability distribution allow just enough special structure to yield a workable theory. This paper catalogs a series of theorems relating log-concavity and/or log-convexity of probability density functions, distribution functions, reliability functions, and their integrals. We list a large number of commonly-used probability distributions and report the log-concavity or log-convexity of their density functions and their integrals. We also discuss a variety of applications of log-concavity that have appeared in the literature.},
  timestamp = {2015-11-15T19:13:06Z},
  number = {2},
  urldate = {2015-11-15},
  journal = {Economic Theory},
  author = {Bagnoli, Mark and Bergstrom, Ted},
  year = {2005},
  pages = {445--469},
  file = {Bagnoli_Bergstrom_2005_Log-Concave Probability and Its Applications.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/G3EB3NPG/Bagnoli_Bergstrom_2005_Log-Concave Probability and Its Applications.pdf:application/pdf}
}

@book{cox_analysis_1984,
  title = {Analysis of {{Survival Data}}},
  isbn = {978-0-412-24490-2},
  abstract = {This monograph contains many ideas on the analysis of survival data to present a comprehensive account of the field. The value of survival analysis is not confined to medical statistics, where the benefit of the analysis of data on such factors as life expectancy and duration of periods of freedom from symptoms of a disease as related to a treatment applied individual histories and so on, is obvious. The techniques also find important applications in industrial life testing and a range of subjects from physics to econometrics. In the eleven chapters of the book the methods and applications of are discussed and illustrated by examples.},
  language = {en},
  timestamp = {2015-11-16T05:50:37Z},
  publisher = {{CRC Press}},
  author = {Cox, D. R. and Oakes, David},
  month = jun,
  year = {1984},
  keywords = {Mathematics / Probability \& Statistics / General,Science / Life Sciences / Biology}
}

@article{laird_covariance_1981,
  title = {Covariance {{Analysis}} of {{Censored Survival Data Using Log}}-{{Linear Analysis Tech}}},
  timestamp = {2015-11-16T08:36:38Z},
  author = {Laird, Nan and Oliver, Donald},
  year = {1981}
}

@article{holford_analysis_1980,
  title = {The Analysis of Rates and of Survivorship Using Log-Linear Models},
  timestamp = {2015-11-16T08:36:58Z},
  urldate = {2015-11-16},
  journal = {Biometrics},
  author = {Holford, Theodore R.},
  year = {1980},
  pages = {299--305}
}

@book{barlow_mathematical_1965,
  title = {Mathematical {{Theory}} of {{Reliability}}},
  isbn = {978-0-471-04965-4},
  abstract = {This monograph presents a survey of mathematical models useful in solving reliability problems. It includes a detailed discussion of life distributions corresponding to wearout and their use in determining maintenance policies, and covers important topics such as the theory of increasing (decreasing) failure rate distributions, optimum maintenance policies, and the theory of coherent systems. The emphasis throughout the book is on making minimal assumptions - and only those based on plausible physical considerations - so that the resulting mathematical deductions may be safely made about a large variety of commonly occurring reliability situations. The first part of the book is concerned with component reliability, while the second part covers system reliability, including problems that are as important today as they were in the 1960s. The enduring relevance of the subject of reliability and the continuing demand for a graduate-level book on this topic are the driving forces behind its re-publication.},
  language = {en},
  timestamp = {2015-11-17T08:12:26Z},
  publisher = {{Wiley}},
  author = {Barlow, Richard E. and Proschan, Frank},
  month = jan,
  year = {1965}
}

@article{kowalski_how_2003,
  title = {How to Recognize a Split-Plot Experiment},
  volume = {36},
  timestamp = {2015-11-17T18:36:33Z},
  number = {11},
  urldate = {2015-11-17},
  journal = {Quality progress},
  author = {Kowalski, Scott M. and Potcner, Kevin J.},
  year = {2003},
  pages = {60--66},
  file = {Kowalski_Potcner_2003_How to recognize a split-plot experiment.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/EAVIS2HI/Kowalski_Potcner_2003_How to recognize a split-plot experiment.pdf:application/pdf}
}

@book{pukelsheim_optimal_1993,
  title = {Optimal {{Design}} of {{Experiments}}},
  isbn = {978-0-89871-910-9},
  abstract = {Optimal Design of Experiments offers a rare blend of linear algebra, convex analysis, and statistics. The optimal design for statistical experiments is first formulated as a concave matrix optimization problem. Using tools from convex analysis, the problem is solved generally for a wide class of optimality criteria such as D-, A-, or E-optimality. The book then offers a complementary approach that calls for the study of the symmetry properties of the design problem, exploiting such notions as matrix majorization and the Kiefer information matrix ordering. The results are illustrated with optimal designs for polynomial fit models, Bayes designs, balanced incomplete block designs, exchangeable designs on the cube, rotatable designs on the sphere, and many other examples. Since the book\&\#39;s initial publication in 1993, readers have used its methods to derive optimal designs on the circle, optimal mixture designs, and optimal designs in other statistical models. Using local linearization techniques, the methods described in the book prove useful even for nonlinear cases, in identifying practical designs of experiments. Audience: anyone involved in planning statistical experiments, including mathematical statisticians, applied statisticians, and mathematicians interested in matrix optimization problems.},
  language = {en},
  timestamp = {2015-11-18T10:10:33Z},
  publisher = {{SIAM}},
  author = {Pukelsheim, Friedrich},
  year = {1993}
}

@book{box_statistics_1978,
  title = {Statistics for Experimenters: An Introduction to Design, Data Analysis, and Model Building},
  isbn = {978-0-471-09315-2},
  shorttitle = {Statistics for Experimenters},
  abstract = {Introduces the philosophy of experimentation and the part that statistics play in experimentation. Emphasizes the need to develop a capability for ``statistical thinking'' by using examples drawn from actual case studies.},
  language = {en},
  timestamp = {2015-11-18T11:21:24Z},
  publisher = {{Wiley}},
  author = {Box, George E. P. and Hunter, William Gordon and Hunter, J. Stuart},
  month = jul,
  year = {1978},
  keywords = {Analisis de varianza,Analisis multivariado,analysis of variance,Diseǫ de experimentos,Experimental design,Mathematics / Probability \& Statistics / General,Science / Research \& Methodology,Technology \& Engineering / Engineering (General)}
}

@book{kalbfleisch_statistical_2002,
  title = {The {{Statistical Analysis}} of {{Failure Time Data}}},
  isbn = {978-0-471-36357-6},
  abstract = {Now entering its fourth edition, the market-leading Handbook of MRI Technique has been fully revised and updated to incorporate new technologies and developments essential to good practice. Written specifically for technologists and highly illustrated, it guides the uninitiated through scanning techniques and helps more experienced technologists to improve image quality. The first part of the book considers the main aspects of theory that relate to scanning and also includes practical tips on gating, equipment use, patient care and safety, and information on contrast media. The second half provides step-by-step instruction for examining each anatomical area, beginning with a basic anatomy section followed by sections on indications, patient positioning, equipment, artefacts and tips on optimizing image quality.  Written by an international team of technologists from the United States, United Kingdom and Europe Suitable for users for all types of MRI systems Now includes key points throughout for quick reference Companion website at www.wiley.com/go/westbrook/mritechnique with self-assessment and image flashcards  Handbook of MRI Technique continues to be the ideal support both for radiographers new to MRI and for regular users looking for information on alternative techniques and suggestions on protocol modifications.},
  language = {en},
  timestamp = {2015-11-18T11:50:04Z},
  publisher = {{Wiley}},
  author = {Kalbfleisch, John D. and Prentice, Ross L.},
  month = sep,
  year = {2002},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{klein_survival_2005,
  title = {Survival {{Analysis}}: {{Techniques}} for {{Censored}} and {{Truncated Data}}},
  isbn = {978-0-387-95399-1},
  shorttitle = {Survival {{Analysis}}},
  abstract = {Applied statisticians in many fields frequently analyze time-to-event data. While the statistical tools presented in this book are applicable to data from medicine, biology, public health, epidemiology, engineering, economics and demography, the focus here is on applications of the techniques to biology and medicine. The analysis of survival experiments is complicated by issues of censoring and truncation. The use of counting process methodology has allowed for substantial advances in the statistical theory to account for censoring and truncation in survival experiments. This book makes these complex techniques accessible to applied researchers without the advanced mathematical background. The authors present the essentials of these techniques, as well as classical techniques not based on counting processes, and apply them to data. The second edition contains some new material as well as solutions to the odd-numbered revised exercises. New material consists of a discussion of summary statistics for competing risks probabilities in Chapter 2 and the estimation process for these probabilities in Chapter 4. A new section on tests of the equality of survival curves at a fixed point in time is added in Chapter 7. In Chapter 8 an expanded discussion is presented on how to code covariates and a new section on discretizing a continuous covariate is added. A new section on Lin and Ying's additive hazards regression model is presented in Chapter 10. We now proceed to a general discussion of the usefulness of this book incorporating the new material with that of the first edition.},
  language = {en},
  timestamp = {2015-11-18T11:50:11Z},
  publisher = {{Springer Science \& Business Media}},
  author = {Klein, John P. and Moeschberger, Melvin L.},
  month = mar,
  year = {2005},
  keywords = {Business \& Economics / Statistics,Mathematics / Probability \& Statistics / General,Medical / Biostatistics,Medical / Epidemiology,Medical / General,Social Science / Methodology,Social Science / Research}
}

@book{venables_modern_2002,
  address = {New York, NY},
  series = {Statistics and Computing},
  title = {Modern {{Applied Statistics}} with {{S}}},
  isbn = {978-1-4419-3008-8 978-0-387-21706-2},
  timestamp = {2015-11-18T12:59:55Z},
  urldate = {2015-11-18},
  publisher = {{Springer New York}},
  author = {Venables, W. N. and Ripley, B. D.},
  editor = {Chambers, J. and Eddy, W. and H{\"a}rdle, W. and Sheather, S. and Tierney, L.},
  year = {2002}
}

@article{dorfman_detection_1943,
  title = {The {{Detection}} of {{Defective Members}} of {{Large Populations}}},
  volume = {14},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177731363},
  abstract = {Project Euclid - mathematics and statistics online},
  language = {EN},
  timestamp = {2015-12-05T14:06:40Z},
  number = {4},
  urldate = {2015-12-05},
  journal = {The Annals of Mathematical Statistics},
  author = {Dorfman, Robert},
  month = dec,
  year = {1943},
  pages = {436--440},
  file = {Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/JDCRH86H/1177731363.html:text/html}
}

@book{john_statistical_1971,
  title = {Statistical Design and Analysis of Experiments},
  timestamp = {2015-12-27T09:25:22Z},
  urldate = {2015-12-27},
  publisher = {{SIAM}},
  author = {John, Peter William Meredith},
  year = {1971},
  file = {Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/36QS4XEI/1.9781611971149.html:text/html}
}

@book{_process_1998,
  address = {London ; New York},
  title = {Process {{Capability Indices}} in {{Theory}} and {{Practice}}},
  isbn = {978-0-340-69177-9},
  language = {English},
  timestamp = {2016-01-13T08:08:17Z},
  publisher = {{Hodder Education Publishers}},
  month = oct,
  year = {1998}
}

@book{hawkins_cumulative_1998,
  address = {New York},
  edition = {1998 edition},
  title = {Cumulative {{Sum Charts}} and {{Charting}} for {{Quality Improvement}}},
  isbn = {978-0-387-98365-3},
  language = {English},
  timestamp = {2016-01-13T08:09:27Z},
  publisher = {{Springer}},
  author = {Hawkins, Douglas M. and Olwell, David H.},
  month = jan,
  year = {1998}
}

@book{acheson_j._duncan_quality_1986,
  address = {Homewood, Ill},
  edition = {5 edition},
  title = {Quality {{Control}} and {{Industrial Statistics}}. {{Fifth Edition}}},
  isbn = {978-0-256-03535-3},
  language = {English},
  timestamp = {2016-01-13T08:09:43Z},
  publisher = {{Irwin}},
  author = {{Acheson J. Duncan}},
  month = jan,
  year = {1986},
  keywords = {Technology \& Engineering / Industrial Engineering}
}

@article{srivastava_testing_2013,
  title = {On Testing the Equality of Mean Vectors in High Dimension},
  volume = {17},
  issn = {2228-4699},
  doi = {10.12697/ACUTM.2013.17.03},
  abstract = {In this article, we review various tests that have been proposed in the literature for testing the equality of several mean vectors. In particular, it includes testing the equality of two mean vectors, the so-called two-sample problem as well as that of testing the equality of several mean vectors, the so-called multivariate analysis of variance or MANOVA problem. The total sample size, however, may be less than the dimension of the mean vectors, and so usual tests cannot be used. Powers of these tests are compared using simulation.},
  language = {en},
  timestamp = {2016-02-01T12:13:48Z},
  number = {1},
  urldate = {2015-06-01},
  journal = {Acta et Commentationes Universitatis Tartuensis de Mathematica},
  author = {Srivastava, Muni S.},
  month = jun,
  year = {2013},
  keywords = {Equality of two mean vectors,high dimensional,inequality of two covariance matrices,Multivariate analysis of variance,sample smaller than dimension},
  pages = {31--56},
  file = {Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/CES3WQ63/Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/52BRBUCE/ACUTM.2013.17.html:text/html}
}

@article{goeman_testing_2006,
  title = {Testing against a High Dimensional Alternative},
  volume = {68},
  issn = {1467-9868},
  doi = {10.1111/j.1467-9868.2006.00551.x},
  abstract = {Summary.\hspace{0.6em} As the dimensionality of the alternative hypothesis increases, the power of classical tests tends to diminish quite rapidly. This is especially true for high dimensional data in which there are more parameters than observations. We discuss a score test on a hyperparameter in an empirical Bayesian model as an alternative to classical tests. It gives a general test statistic which can be used to test a point null hypothesis against a high dimensional alternative, even when the number of parameters exceeds the number of samples. This test will be shown to have optimal power on average in a neighbourhood of the null hypothesis, which makes it a proper generalization of the locally most powerful test to multiple dimensions. To illustrate this new locally most powerful test we investigate the case of testing the global null hypothesis in a linear regression model in more detail. The score test is shown to have significantly more power than the F-test whenever under the alternative the large variance principal components of the design matrix explain substantially more of the variance of the outcome than do the small variance principal components. The score test is also useful for detecting sparse alternatives in truly high dimensional data, where its power is comparable with the test based on the maximum absolute t-statistic.},
  language = {en},
  timestamp = {2016-02-02T10:24:22Z},
  number = {3},
  urldate = {2016-02-02},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  author = {Goeman, Jelle J. and Van De Geer, Sara A. and Van Houwelingen, Hans C.},
  month = jun,
  year = {2006},
  keywords = {Empirical Bayes modelling,F-test,High dimensional data,Hypothesis testing,Locally most powerful test,Power,Score test},
  pages = {477--493},
  file = {Goeman et al_2006_Testing against a high dimensional alternative.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/8C4IWRI6/Goeman et al_2006_Testing against a high dimensional alternative.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/5UCM6VBI/full.html:text/html}
}

@book{montgomery_statistical_2012,
  address = {Hoboken, NJ},
  edition = {7 edition},
  title = {Statistical {{Quality Control}}},
  isbn = {978-1-118-14681-1},
  language = {English},
  timestamp = {2016-02-06T10:27:13Z},
  publisher = {{Wiley}},
  author = {Montgomery, Douglas C.},
  month = jun,
  year = {2012}
}

@book{_jurans_1988,
  address = {New York},
  title = {Juran's {{Quality Control Handbook}}},
  isbn = {978-0-07-033176-1},
  language = {English},
  timestamp = {2016-02-06T10:27:47Z},
  publisher = {{Mcgraw-Hill}},
  month = aug,
  year = {1988}
}

@article{goeman_multiple_2011,
  title = {Multiple {{Testing}} for {{Exploratory Research}}},
  volume = {26},
  issn = {0883-4237},
  abstract = {Motivated by the practice of exploratory research, we formulate an approach to multiple testing that reverses the conventional roles of the user and the multiple testing procedure. Traditionally, the user chooses the error criterion, and the procedure the resulting rejected set. Instead, we propose to let the user choose the rejected set freely, and to let the multiple testing procedure return a confidence statement on the number of false rejections incurred. In our approach, such confidence statements are simultaneous for all choices of the rejected set, so that post hoc selection of the rejected set does not compromise their validity. The proposed reversal of roles requires nothing more than a review of the familiar closed testing procedure, but with a focus on the non-consonant rejections that this procedure makes. We suggest several shortcuts to avoid the computational problems associated with closed testing.},
  timestamp = {2016-02-14T08:02:41Z},
  number = {4},
  urldate = {2016-02-14},
  journal = {Statistical Science},
  author = {Goeman, Jelle J. and Solari, Aldo},
  year = {2011},
  pages = {584--597},
  file = {Goeman_Solari_2011_Multiple Testing for Exploratory Research.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZIJ568RA/Goeman_Solari_2011_Multiple Testing for Exploratory Research.pdf:application/pdf}
}

@article{li_using_2012,
  title = {Using P Values to Design Statistical Process Control Charts},
  volume = {54},
  issn = {0932-5026, 1613-9798},
  doi = {10.1007/s00362-012-0447-0},
  abstract = {Conventional Phase II statistical process control (SPC) charts are designed using control limits; a chart gives a signal of process distributional shift when its charting statistic exceeds a properly chosen control limit. To do so, we only know whether a chart is out-of-control at a given time. It is therefore not informative enough about the likelihood of a potential distributional shift. In this paper, we suggest designing the SPC charts using p values. By this approach, at each time point of Phase II process monitoring, the p value of the observed charting statistic is computed, under the assumption that the process is in-control. If the p value is less than a pre-specified significance level, then a signal of distributional shift is delivered. This p value approach has several benefits, compared to the conventional design using control limits. First, after a signal of distributional shift is delivered, we could know how strong the signal is. Second, even when the p value at a given time point is larger than the significance level, it still provides us useful information about how stable the process performs at that time point. The second benefit is especially useful when we adopt a variable sampling scheme, by which the sampling time can be longer when we have more evidence that the process runs stably, supported by a larger p value. To demonstrate the p value approach, we consider univariate process monitoring by cumulative sum control charts in various cases.},
  language = {en},
  timestamp = {2016-04-04T09:38:03Z},
  number = {2},
  urldate = {2016-04-04},
  journal = {Statistical Papers},
  author = {Li, Zhonghua and Qiu, Peihua and Chatterjee, Snigdhansu and Wang, Zhaojun},
  month = apr,
  year = {2012},
  keywords = {bootstrap,Cumulative sum control charts,Economic Theory,Operations Research/Decision Theory,Probability Theory and Stochastic Processes,Process monitoring,Self-starting,Statistics for Business/Economics/Mathematical Finance/Insurance,Variable sampling},
  pages = {523--539},
  file = {Li et al_2012_Using p values to design statistical process control charts.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/35EHAWRJ/Li et al_2012_Using p values to design statistical process control charts.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TJWMRMI2/s00362-012-0447-0.html:text/html}
}

@article{liu_control_1995,
  title = {Control {{Charts}} for {{Multivariate Processes}}},
  volume = {90},
  issn = {0162-1459},
  doi = {10.2307/2291529},
  abstract = {This article uses the concept of data depth to introduce several new control charts for monitoring processes of multivariate quality measurements. For any dimension of the measurements, these charts are in the form of two-dimensional graphs that can be visualized and interpreted just as easily as the well-known univariate X, X\=, and CUSUM charts. Moreover, they have several significant advantages. First, they can detect simultaneously the location shift and scale increase of the process, unlike the existing methods, which can detect only the location shift. Second, their construction is completely nonparametric; in particular, it does not require the assumption of normality for the quality distribution, which is needed in standard approaches such as the $\chi$2 and Hotelling's T2 charts. Thus these new charts generalize the principle of control charts to multivariate settings and apply to a much broader class of quality distributions.},
  timestamp = {2016-04-05T05:36:38Z},
  number = {432},
  urldate = {2016-04-05},
  journal = {Journal of the American Statistical Association},
  author = {Liu, Regina Y.},
  year = {1995},
  pages = {1380--1387}
}

@book{wilcox_introduction_2005,
  title = {Introduction to {{Robust Estimation}} and {{Hypothesis Testing}}},
  isbn = {978-0-12-751542-7},
  abstract = {This revised book provides a thorough explanation of the foundation of robust methods, incorporating the latest updates on R and S-Plus, robust ANOVA (Analysis of Variance) and regression. It guides advanced students and other professionals through the basic strategies used for developing practical solutions to problems, and provides a brief background on the foundations of modern methods, placing the new methods in historical context. Author Rand Wilcox includes chapter exercises and many real-world examples that illustrate how various methods perform in different situations.Introduction to Robust Estimation and Hypothesis Testing, Second Edition, focuses on the practical applications of modern, robust methods which can greatly enhance our chances of detecting true differences among groups and true associations among variables. * Covers latest developments in robust regression* Covers latest improvements in ANOVA* Includes newest rank-based methods* Describes and illustrated easy to use software},
  language = {en},
  timestamp = {2016-04-09T19:27:08Z},
  publisher = {{Academic Press}},
  author = {Wilcox, Rand R.},
  year = {2005},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Regression Analysis,Psychology / Education \& Training}
}

@misc{_nist/sematech_????,
  title = {{{NIST}}/{{SEMATECH}} E-{{Handbook}} of {{Statistical Methods}}},
  timestamp = {2016-04-10T07:33:30Z},
  urldate = {2016-04-04},
  howpublished = {\url{http://www.itl.nist.gov/div898/handbook/index.htm}},
  file = {NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/7SPXIWCS/index.html:text/html;NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/9552ZZPS/index.html:text/html;NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/N27E6HVK/index.html:text/html;NIST/SEMATECH e-Handbook of Statistical Methods:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/PNNFE43M/index.html:text/html}
}

@article{hotelling_generalization_1931,
  title = {The {{Generalization}} of {{Student}}'s {{Ratio}}},
  volume = {2},
  issn = {0003-4851, 2168-8990},
  doi = {10.1214/aoms/1177732979},
  abstract = {Project Euclid - mathematics and statistics online},
  language = {EN},
  timestamp = {2016-04-10T07:33:59Z},
  number = {3},
  urldate = {2015-06-19},
  journal = {The Annals of Mathematical Statistics},
  author = {Hotelling, Harold},
  month = aug,
  year = {1931},
  pages = {360--378},
  file = {Hotelling_1931_The Generalization of Student's Ratio.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/2HEC4VV3/Hotelling_1931_The Generalization of Student's Ratio.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/MRVQTBMM/1177732979.html:text/html;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/VH7S648S/1177732979.html:text/html}
}

@book{fujikoshi_multivariate_2011,
  title = {Multivariate {{Statistics}}: {{High}}-{{Dimensional}} and {{Large}}-{{Sample Approximations}}},
  isbn = {978-0-470-53986-6},
  shorttitle = {Multivariate {{Statistics}}},
  abstract = {A comprehensive examination of high-dimensional analysis of multivariate methods and their real-world applications Multivariate Statistics: High-Dimensional and Large-Sample Approximations is the first book of its kind to explore how classical multivariate methods can be revised and used in place of conventional statistical tools. Written by prominent researchers in the field, the book focuses on high-dimensional and large-scale approximations and details the many basic multivariate methods used to achieve high levels of accuracy. The authors begin with a fundamental presentation of the basic tools and exact distributional results of multivariate statistics, and, in addition, the derivations of most distributional results are provided. Statistical methods for high-dimensional data, such as curve data, spectra, images, and DNA microarrays, are discussed. Bootstrap approximations from a methodological point of view, theoretical accuracies in MANOVA tests, and model selection criteria are also presented. Subsequent chapters feature additional topical coverage including:  High-dimensional approximations of various statistics High-dimensional statistical methods Approximations with computable error bound Selection of variables based on model selection approach Statistics with error bounds and their appearance in discriminant analysis, growth curve models, generalized linear models, profile analysis, and multiple comparison  Each chapter provides real-world applications and thorough analyses of the real data. In addition, approximation formulas found throughout the book are a useful tool for both practical and theoretical statisticians, and basic results on exact distributions in multivariate analysis are included in a comprehensive, yet accessible, format. Multivariate Statistics is an excellent book for courses on probability theory in statistics at the graduate level. It is also an essential reference for both practical and theoretical statisticians who are interested in multivariate analysis and who would benefit from learning the applications of analytical probabilistic methods in statistics.},
  language = {en},
  timestamp = {2016-05-01T07:19:13Z},
  publisher = {{John Wiley \& Sons}},
  author = {Fujikoshi, Yasunori and Ulyanov, Vladimir V. and Shimizu, Ryoichi},
  month = aug,
  year = {2011},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@book{cano_six_2012,
  title = {Six {{Sigma}} with {{R}}: {{Statistical Engineering}} for {{Process Improvement}}},
  isbn = {978-1-4614-3651-5},
  shorttitle = {Six {{Sigma}} with {{R}}},
  abstract = {Six Sigma has arisen in the last two decades as a breakthrough Quality Management Methodology. With Six Sigma, we are solving problems and improving processes using as a basis one of the most powerful tools of human development: the scientific method. For the analysis of data, Six Sigma requires the use of statistical software, being R an Open Source option that fulfills this requirement. R is a software system that includes a programming language widely used in academic and research departments. Nowadays, it is becoming a real alternative within corporate environments. The aim of this book is to show how R can be used as the software tool in the development of Six Sigma projects. The book includes a gentle introduction to Six Sigma and a variety of examples showing how to use R within real situations. It has been conceived as a self contained piece. Therefore, it is addressed not only to Six Sigma practitioners, but also to professionals trying to initiate themselves in this management methodology. The book may be used as a text book as well.},
  language = {en},
  timestamp = {2016-08-02T08:28:34Z},
  publisher = {{Springer New York}},
  author = {Cano, Emilio L. and Moguerza, Javier M. and Redchuk, Andr{\'e}s},
  month = jul,
  year = {2012},
  keywords = {Business \& Economics / Statistics,Computers / Mathematical \& Statistical Software,Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes,Medical / Biostatistics}
}

@article{best_walter_2006,
  title = {Walter {{A Shewhart}}, 1924, and the {{Hawthorne}} Factory},
  volume = {15},
  issn = {1475-3898},
  doi = {10.1136/qshc.2006.018093},
  timestamp = {2016-08-26T20:27:10Z},
  number = {2},
  urldate = {2016-08-26},
  journal = {Quality \& Safety in Health Care},
  author = {Best, M and Neuhauser, D},
  month = apr,
  year = {2006},
  pages = {142--143},
  file = {Best_Neuhauser_2006_Walter A Shewhart, 1924, and the Hawthorne factory.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/S437N5R2/Best_Neuhauser_2006_Walter A Shewhart, 1924, and the Hawthorne factory.pdf:application/pdf},
  pmid = {16585117},
  pmcid = {PMC2464836}
}

@book{cox_principles_2011,
  title = {Principles of {{Applied Statistics}}},
  isbn = {978-1-107-64445-8},
  abstract = {Applied statistics is more than data analysis, but it is easy to lose sight of the big picture. David Cox and Christl Donnelly distil decades of scientific experience into usable principles for the successful application of statistics, showing how good statistical strategy shapes every stage of an investigation. As you advance from research or policy question, to study design, through modelling and interpretation, and finally to meaningful conclusions, this book will be a valuable guide. Over a hundred illustrations from a wide variety of real applications make the conceptual points concrete, illuminating your path and deepening your understanding. This book is essential reading for anyone who makes extensive use of statistical methods in their work.},
  language = {en},
  timestamp = {2016-12-01T07:43:14Z},
  publisher = {{Cambridge University Press}},
  author = {Cox, D. R. and Donnelly, Christl A.},
  month = jul,
  year = {2011},
  note = {Google-Books-ID: Uel0MgEACAAJ},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Epidemiology}
}


