\chapter{Acceptance Sampling}
\chaptermark{Acceptance}

% AQL
% LTPD
% RQL
% LQL
% Type A and Type B RO curves.

We can improve quality (read- conformance to specification) by introducing an inspection stage in our process.
Clearly, a full inspection is time consuming. 
It may also be destructive (you don't want to re-package ice-cream after checking its texture \dots).
No-inspection may be appropriate if you don't particularly care about your brand, or if production has very high capability indices.
A reasonable, intermediate approach, is a partial random inspection, known as \emph{acceptance sampling}.
As the name suggests, in acceptance sampling, one samples, then checks, then accepts (or not).

Acceptance sampling can be seen as a control chart monitoring that triggers active intervention in the production. As such ,it is a crude type of \emph{engineering control} (Sec.~\ref{sec:terminology_statistical}).
The intervention is obvious. The monitoring is based on some continuous (variable) or discrete (attribute) of a sample of units from a \emph{batch}, \aka, a \emph{lot}.
Seen as a feedback control, it is not surprising that when designing an acceptance sampling scheme, we have similar decisions as when designing a control chart:
\begin{enumerate}
\item What is a batch? Just like choosing the sampling frequency in a Shewart chart. 
We would like homogenous batches, i.e., with low inner variability. A box, a shipment, a day's production, are typical batches. 
\item Within batch sampling scheme: just like rational grouping in Shewart chart. Typical approaches include \emph{single sampling plans}, \emph{double}, \emph{multiple}, and \emph{sequential sampling plans}.
This can be seen as the design of an experiment to be performed on each batch.
\item How many units? Just like choosing the sample size in a Shewart chart.
\item Decision cutoff: Just like setting control limits in a Shewart chart. 
\end{enumerate}
We can readily see that the design of an acceptance sampling scheme is very similar to the design of a control chart. 
We may construct an full blown economical optimization problem to design the sampling, as we did in Section~\ref{sec:economical_considerations}. Just like control charts, however, it is more common to design sampling schemes using ``first-order'' power considerations. 
For this reason, the \emph{power function} will play a crucial role.

\section{Acceptance Sampling Terminology}
Adapted from \cite{natrella_nist/sematech_2010}.
\begin{description}
\item [LASP] A \emph{lot acceptance sampling plan}, ultimately, a statistical test at the end of which we either accept a batch. In this text we typically use the \emph{batch acceptance sampling scheme} for the same purpose. 
\item [AQL] The \emph{acceptable quality level}, or \emph{acceptable quality limit}, is the highest proportion of defects acceptable to the producer. 
\item [LTPD] The \emph{lot tolerance percent defective} is the highest proportion of defects acceptable to the consumer. Clearly, $AQL<LTPD$. LTPD is also known as \emph{rejectable quality level} (RQL), and \emph{ limiting quality level} (LQL). 
\item [OC Curve] The \emph{operating characteristic curve} is the power function of an LSAP.
\item [Type-A and Type-B OC Curves] A \emph{Type-A OC curve} is one computed assuming sampling from batches is done without replacement. Conversely, a \emph{Type-B OC curve} is computed assuming sampling with replacement.
\item [Producer's Risk] The \emph{producer's risk} is throwing away good batches. Formally, this is the probability of rejecting a batch with less than AQL defects. We consider there type-I errors.
\item [Consumer's Risk] The \emph{consumer's risk} is accepting bad batches. Formally, this is the probability of accepting a batch with more than LTPD defects. We consider there type-II errors.
\item [Rectifying Inspection] An LASP where lots are not rejected but rather rectified. 
\end{description}



\section{Single Sampling Scheme}
In the simplest LASP we base our decisions on a single random sample from each batch.
This obviously facilitates the statistical analysis of the properties of this LASP.

\subsubsection{Type-B Power Function}

When sampling $n$ units from a batch with a proportion of $p$ defects, then the number of defects $\x \sim Binom(n,p)$.
If we reject a batch when more than $c$ defects are found, then the power function of a type-B LASP is given by
\begin{align}
\label{eq:power_accpet}
	\pi_{n,c}(p)=P(\x \geq c)= \sum_{k=c}^n \binom{n}{k} p^k (1-p)^{1-k} .
\end{align}
Eq.(\ref{eq:power_accpet}) may be evaluated manually, or with the \rcode{pbinom()} \R function. 

Just like any other hypothesis test, it is common practice to set $n,c$ so that control both the consumer's risk ($\beta_{n,c}=1-\pi_{n,c}$) and the producer's risk ($\alpha_{n,c}$).
By adopting a the hypothesis testing philosophy, we solve $n,c$ so that 
\begin{align}
\label{eq:power_acceptance}
 \min \set{n : \pi_{n,c}\geq \pi_0 \quad and \quad \alpha_{n,c}\leq \alpha_0 }.
\end{align}
For relating the LASP terminology to this problem, we need to observe that $$\alpha_{n,c}=\pi_{n,c}(p=AQL)$$ and $$\pi_{n,c}=\pi_{n,c}(p=LTPD).$$
For a producer who does not want to reject batches where $AQL=10\%$ defects, with more than $\alpha_0=10\%$; 
and a consumer who does not want to accept batches where $LTPD=30\%$, with less than $\pi_0=80\%$, 
we have that their LASP would take $n=33$ samples, and reject a batch whenever the $\x>4$, when $n=21$.
\begin{remark}[Approximate Power Calculations]
The problem to solve in Eq.(\ref{eq:power_acceptance}) requires some non trivial iterations because of the discrete nature.
It is quite more convenient to replace the exact form of Eq.(\ref{eq:power_accpet}) with a normal approximation, so that Eq.(\ref{eq:power_acceptance}) has a closed form solution. 
\end{remark}



\subsubsection{Type-A Power Function}
It is quite wired that we would sample with replacement from a batch.
It is quite more probable that we used the replacement assumption, only as an approximation because $n$ is small compared to the batch size $N$. 
If this is not the case, the binomial distribution in Eq.(\ref{eq:power_accpet}) should be replaced with the Hypergeometric distribution. 
For all practical purposes, this means using the \rcode{phyper()} \R function, instead of \rcode{pbinom()}.



\subsection{Double Sampling Scheme}
In a double sampling scheme, we first example $n_1$ units. 
We may then decide to accept, reject, or sample another $n_2$ units. 
After those $n_2$ samples, we can accept or reject. 
The idea of a power function remains the same, even if calculations are slightly more cumbersome.
Here is our our policy:
For $x_1$ computed on the first $n_1$ samples:
If $x_1  < a_1$ then accept the batch;
If $x_1 \geq  c_1$ then reject the batch;
Otherwise, compute $x_2$ with $n_1+n_2$ samples.
If $x_2 < a_2$ accept the batch;
If $x_2 \geq c_2$ then reject the batch.

For brevity, we denote all the design parameters of the scheme by $\gamma:= (n_1,n_2,c_1,c_2,a_1,a_2)$. 
The power function of such a scheme would thus be:
\begin{align}
	\pi_\gamma &:= P(\set{\x_1 \geq c_1} \union \set{\x_1 \in [a_1,c_1], \x_2 \geq c_2}) \\
	&= P(\x_1 \geq c_1) + \sum_{k=a_1}^{c_1} P(\x_1 =k, \x_2-\x_1 \geq c_2-k) \\
		&= P(\x_1 \geq c_1) + \sum_{k=a_1}^{c_1} P(\x_1 =k) P(\x_2-\x_1 \geq c_2-k).
\end{align}
We may now use the fact that $\x_1 \sim Binom(n_1,p)$ and that $\x_2-\x_1 \sim Binom(n_2,p)$, and quickly compute the power in \R.

\begin{remark}[Redundancy]
Unlike the single stage LASP, where we have two equations with two variables, in the two-stage case there are many $\gamma$ configurations that will achieve given consumer and producer risks ($\alpha_0,\pi_0$).
The choice of the particular configuration should depend on the type of signal we expect. 
For quick detection of strong signal (large $p$), choose small $n_1$. 
For sensitive detection of subtle signal, choose large $n_1$. 
\end{remark}

\begin{remark}[No Free Lunch]
While it may seem that a two stage LASP is always better than a single stage LASP, this is not the case.
To see why, consider a weak signal ($p$ close to AQL). We may need all $n_1+n_2$ samples to get decent power. The first stage then add nothing except logistic complications.
\end{remark}


\section{Sequential Scheme}
At this point you should be thinking: why only two stages? 
Clearly we may reject or accept a sample as each unit comes in.
This is exactly what Sequential LASPs are all about.
We will not give the details, except the observation that this is merely a type of sequential experiment as described in Section~\ref{sec:sequantial}.
